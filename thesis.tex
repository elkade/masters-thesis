\documentclass[12pt, twoside, openany]{report}
\usepackage[dvips]{graphicx,color,rotating}
\usepackage[cp1250]{inputenc}
\usepackage{t1enc}
\usepackage{a4wide}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{verbatim}
%\usepackage[MeX]{polski}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{left=25mm,right=25mm,bindingoffset=10mm, top=25mm, bottom=25mm}
\usepackage{amssymb, latexsym}
\usepackage{amsthm}
\usepackage{palatino}
\usepackage{array}
\usepackage{pstricks}
\usepackage{textcomp}
\usepackage{float}
\usepackage[none]{hyphenat}
\usepackage[english, polish]{babel}
\usepackage{hyperref}
\theoremstyle{definition}
\newtheorem{theorem}{Twierdzenie}[section]
\newtheorem{remark}{Uwaga}[section]
\newtheorem{definition}{Definicja}[section]
\newtheorem{alg}{Algorytm}[chapter]
\newtheorem{prz}{Przypadek}[section]
\newtheorem{np}{Przyk³ad}[section]
\newtheorem{lemma}[theorem]{Lemat}
\linespread{1.5}
\usepackage{indentfirst}
\newcommand*{\norm}[1]{\left\Vert{#1}\right\Vert}
\newcommand*{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand*{\om}{\omega}
\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}
%\renewcommand{\floatpagefraction}{.99}%
\author{£ukasz Dragan}
\title{Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce}

\begin{document}
\sloppy
\hyphenpenalty 10000
\exhyphenpenalty 10000
\righthyphenmin 10000
\lefthyphenmin 10000
\hyphenchar\font=-1
% Za³ó³æ gêœl¹ jaŸñ.
\begin{titlepage}
\pagestyle{empty}

\noindent
\begin{Large}
\begin{table}[t]
\centering
\begin{tabular}[t]{lcr}
 \includegraphics[width=70pt,height=70pt]{PW} & POLITECHNIKA WARSZAWSKA & \includegraphics[width=70pt,height=70pt]{MiNI}\\
& WYDZIA£ MATEMATYKI & \\
& I NAUK INFORMACYJNYCH &
\end{tabular}
\end{table}

\begin{center}PRACA DYPLOMOWA MAGISTERSKA\end{center}
\begin{center}INFORMATYKA\end{center}\end{Large}
\begin{center}
\Large
\textbf{Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce}
\vfill
\large
\textbf{Content-based recommendations in e-commerce services}
\vfill
\normalsize
Autor:\\
\LARGE
£ukasz Dragan
\vfill
\normalsize
Promotor: 
\large
dr in¿. Anna Wróblewska
\vfill
\large
Warszawa, czerwiec 2017
\end{center}
\newpage
\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}


% \maketitle
\end{titlepage}
\thispagestyle{empty}
\newpage
\pagestyle{headings}
\setcounter{page}{1}
\hyphenation{Syl-ves-tra}
\hyphenation{Syl-ves-ter-a}

\begin{abstract}%DONE
	
	Tematyka niniejszej pracy skupia siê wokó³ zagadnieñ okreœlania podobieñstwa semantycznego pomiêdzy dokumentami tekstowymi i rekomendacji dokumentów podobnych do danego. Szczegó³owy problem pochodzi z internetowego serwisu aukcyjnego Allegro, który posiada dzia³ artyku³ów opisuj¹cych produkty dostêpne w serwisie. W dziale tym funkcjonuje system rekomendacji podobnych artyku³ów tekstowych w oparciu o ich treœæ. Celem pracy jest zbadanie mo¿liwoœci usprawnienia dzia³ania istniej¹cego systemu rekomandacji.
	
	W niniejszej pracy adaptujê dostêpne metody okreœlania podobieñstwa pomiêdzy dokumentami testowymi do powy¿szego problemu, wprowadzam miary umo¿liwiaj¹ce ocenê dzia³ania tych metod oraz dokonujê analizy mo¿liwoœci ich wykorzystania w rzeczywistym systemie. Skupiam siê szczególnie na metodach opartych o semantyczn¹ analizê tekstu.
\end{abstract}

\begin{otherlanguage}{english}
	\begin{abstract}%TODO przet³umaczyæ
		
	\end{abstract}
\end{otherlanguage}

\tableofcontents
\clearpage
%-----------Pocz¹tek czêœci zasadniczej-----------

\chapter{Wstêp}%TODO skorygowaæ

Systemy rekomendacji s¹ powszechnym elementem wielu serwisów internetowych. Sprawdzaj¹ siê na takich polach, jak polecanie produktów w sklepie czy rekomendacje ofert pracy. Daj¹ u¿ytkownikowi poczucie indywidualnego traktowania przez serwis internetowy dopasowuj¹cy niejako zawartoœæ swoich stron to konkretnego u¿ytkownika. Pozwala to u¿ytkownikowi na bardziej efektywne korzystanie z serwisu. Mo¿e to prowadziæ do wiêkszego zaanga¿owania ze strony u¿ytkownika i przywi¹zania do serwisu. Systemy rekomendacji daj¹ obopuln¹ korzyœæ zarówno u¿ytkownikowi jak i w³aœcicielowi serwisu internetowego.

Celem niniejszej pracy magisterskiej jest analiza mo¿liwoœci usprawnienia istniejacego systemu rekomendacji o oparciu o adaptacjê istniej¹cych metod wyszukiwania semantycznego podobieñstwa pomiêdzy dokumentami tekstowymi. Rzeczony system rekomendacji istnieje w internetowym serwisie e-commerce Allegro w dziale artyku³ów tekstowych o tematyce zwi¹zanej z produktami dostêpnymi za poœrednictwem serwisu. System ma na celu zarekomendowanie u¿ytkownikowi artyku³ów o tematyce podobnej do tego, który znajduje siê na stornie aktualnie odwiedzanej przez uzytkownika.

W swojej pracy badam mo¿liwoœæ u¿ycia istniej¹cych metod semantycznej analizy tekstu w odniesieniu do opisanego problemu. Badane metody to Latent Dirichlet Allocation oraz word2vec z wariantem Word Mover's Dictance oraz bez niego.

Podczas prowadzenia badañ stworzy³em szereg skryptów przetwarzaj¹cych dane i wykorzystuj¹cych implementacje opisywanych w tej pracy metod. Opis u¿ytych narzêdzi programistycznych i bibliotek zawar³em w dodatku A do niniejszej pracy.

\section{Rekomendacje artyku³ów tekstowych w Allegro}%TODO potrzebne przypisy
% do 'najwiêksz¹'
%TODO przeredagowaæ


Allegro jest najwiêksz¹ dzia³aj¹c¹ na rynku polskim platform¹ aukcyjn¹ on-line. Posiada ponad 20 mln zarejestrowanych klientów. Ka¿dego dnia na Allegro sprzedaje siê ponad 870 tysiêcy przedmiotów. Zatrudnia 1300 pracowników.\cite{allegro} Serwis umo¿liwia u¿ytkownikom wystawianie na sprzeda¿ oraz kupno przedmiotów poprzez mechanizm licytacji lub natychmiastowego zakupu. Allegro pobiera prowizjê za dokonanie sprzeda¿y za swoim poœrednictwem.

Oprócz g³ównej czêœci serwisu odpowiedzialnej za transakcje Allegro posiada dzia³ zajmuj¹cy siê publikacj¹ artyku³ów opisuj¹cych produkty wystawiane za poœrednictwem serwisu. Ma to na celu pomoc u¿ytkownikom przy wyborze interesuj¹cego ich produktu.

Po to, aby zachêciæ u¿ytkowników do zapoznania siê z treœci¹ kolejnych artyku³ów, zastosowany zosta³ tu system rekomendacji przyporz¹dkowuj¹cy danemu artyku³owi listê powi¹zanych artyku³ów. Kryterium mówi¹cym, czy artyku³y s¹ powi¹zane jest tutaj jedynie treœæ artyku³ów a nie wczeœciejsze zachowanie u¿ytkownika.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{img/screen_allegro.png}
	\caption{Widok strony internetowej zawieraj¹cej jeden z artyku³ów serwisu Allegro. \cite{screen_allegro}}
\end{figure}

Od serwisu Allegro otrzyma³em zserializowan¹ kopiê 20000 artyku³ów dostêpnych na stronach serwisu. Pojedynczy artyku³ sk³ada siê z g³ównej zawartoœci tekstowej oraz metadanych. W celu otrzymania wszelkich danych od firmy Allegro wynagane by³o, abym podpisa³ umowê, w której zobowi¹zujê siê do nieujawniania ¿adnych danych, które otrzyma³em. St¹d opisy danych, na których pracujê, zawarte w tej pracy nie wnikaj¹ w ich szczegó³y i nieodbiegaj¹ od informacji publicznie dostêpnych za poœrednictwem strony pod adresem /url{https://allegro.pl}.

%W niniejszej pracy wykonujê eksperymenty wykorzystuj¹c znane metody okreœlania podobieñstw pomiêdzy dokumentami, które adaptujê do zbioru dokumentów, które otrzyma³em od serwisu Allegro.
%
%W obszarze, którym zajmuje siê niniejsza praca, bezpoœrednim celem rekomendacji jest, aby u¿ytkownik odwiedza³ kolejne podstrony serwisu, co wprost zwiêksza szansê na dokonanie przez niego transakcji.
%
%Obecnie wykorzystywana metoda generowania rekomendacji artyku³ów opiera siê o zapytanie do us³ugi Elasticsearch. Elasticsearch jest popularnym silnikiem wyszukiwania tekstu opartym o indeks Lucene. Dzia³a w architekturze rozproszonej a komunikacja z nim nastêpuje poprzez protokó³ HTTP i format JSON.
%
%Metoda ta ogranicza siê jednak jedynie do wyszukiwania tekstowego pomijaj¹c zagadnienia semantyczne. Znaczy to, ¿e je¿eli dwa teksty opisuj¹ ten sam temat, ale u¿ywaj¹ to tego ró¿nych s³ów, np. synonimów, to systemowi opartemu jedynie o wyszukiwanie tekstowe nie uda siê stwierdziæ podobieñstwa miêdzy tymi tekstami, mimo, i¿ takowe istnieje.
%
%St¹d w mojej pracy postanowi³em wykonaæ eksperymenty z metodami u¿ywaj¹cymi semantycznej analizy tekstu, aby oceniæ, czy daj¹ one lepsze rezultaty od obecnie stosowanej metody.
%
%W niniejszej pracy skupiam siê g³ównie na podejœciu word2vec z racji tego, i¿ powsta³ niedawno.
%
%
%Dochodzenie nowych rekomendacji - nie jest tematem pracy
%
%
%napisaæ, ¿e jêzyk polski stanowi trudnoœæ
%-------------------
%
%S³owa, które zostaj¹ po tokenizacji to np literówki

\section{Struktura pracy}
Rozdzia³ 2 wprowadza do zagadnienia rekomendacji i opisuje wybrane metody przetwarzania jêzyka naturalnego s³u¿¹ce do wyszukiwania podobieñstw miêdzy dokumentami tekstowymi.

Nastêpnie w rozdziale 3 dokonujê opisu konkretnego problemu, jakim jest generacja rekomendacji artyku³ów tekstowych w serwisie Allegro. Opisujê dane otrzymane z serwisu oraz kolejne wstêpnego etapy przetwarzania ich, aby nadawa³y siê do zaaplikowania do nich wybranych metod.

Dalej, w rozdziale 4 opisujê stworzone i zastosowane póŸniej metody ewaluacji wyników.

Nastêpnie w rozdziale 5 opisujê proces zastosowania wybranych metod oraz porównanie efektów ich dzia³ania. 

Ostatecznie w rozdziale 6 dokonujê podsumowania przeprowadzonych badañ i rozwa¿am kierunki dalszych prac w tej dziedzinie.

Za³¹cznik A zawiera opis narzêdzi programistycznych i bibliotek wykorzystanych przez mnie podczas prowadzenia badañ.

\section{Uwagi}

\subsection{}

W celu unikniêcia nieporozumieñ pragnê tutaj zaznaczyæ ró¿nicê pomiêdzy znaczeniami s³owa ,,artyku³'', które mo¿e oznaczaæ zarówno tekst publicystyczny, literacki lub naukowy jak i rzecz, która jest przedmiotem handlu.\cite{slownik} W niniejszej pracy skupiam siê na rekomendacjach artyku³ów tekstowych, st¹d u¿ywam pierwszego znaczenia (chyba, ¿e inne znaczenie jest wyraŸnie zaznaczone).

%TODO
%\subsection{}
%
%W niniejszej pracy operujê na statycznym zbiorze artyku³ów pochodz¹cych wprost z serwisu (styczeñ 2017). Serwis Allegor dynamiczne ewoluuje, st¹d czêœæ 

\chapter{Przegl¹d wybranych metod}

W swojej pracy wykorzystujê i adaptujê do swoich potrzeb szereg metod i narzêdzi umo¿liwiaj¹cych przetwarzanie jêzyka naturalnego, semantyczn¹ analizê tekstu i wykrywanie podobieñstwa pomiêdzy tekstami. Czêœæ z nich (metoda tf-idf, bag-of-words, silnik Elasticsearch) jest od lat powszechnie wykorzystywana w zadaniu wyszukiwania tekstowego. Inne z kolei - korzystaj¹ce z semantycznej analizy tekstu - nie s¹ tak popularne z powodu swojej nowoœci, b¹dŸ trudnoœci w zaaplikowaniu. Daje to pole do badañ i ewentualnych usprawnieñ istniej¹cych systemów opieraj¹cych siê o klasyczne metody. Wybrane metody stosujê, zgodnie z tematem pracy, w zadaniu generowania rekomendacji, st¹d przegl¹d metod zaczynam w³aœnie od wprowadzenia do tego zagadnienia.

\section{Systemy rekomendacji}

Systemy rekomendacji to narzêdzia i techniki maj¹ce na celu zasugerowaæ u¿ytkownikowi przedmioty. Sugestie te odnosz¹ siê do ró¿nych procesów podejmowania decyzji takich jak np. które artyku³y kupiæ, jakiej muzyki s³uchaæ czy te¿ które wiadomoœci czytaæ. ,,Przedmiot'' jest tutaj ogólnym pojêciem oznaczaj¹cym coœ, co system poleca u¿ytkownikowi. \cite{handbook} 

Przy wci¹¿ wzrastaj¹cej iloœci danych u¿ytkownicy serwisów internetowych czêsto nie s¹ w stanie dotrzeæ do informacji, która ich interesuje. Jest to pole do rozwoju zautomatyzowanych systemów rekomendacyjnych polecaj¹cych u¿ytkownikom treœci, które mog¹ ich zainterezowaæ. Dzia³alnoœæ tekiego systemu daj zysk zarówn u¿ytkownikowi, pozwalaj¹c mu dotrzeæ do informacji, której móg³by samodzielnie nie odszukaæ, albo wrêcz nie wiedzieæ, i¿ taka informacja istnieje, jak i dla w³aœcicieli serwisów internetowych, którym zale¿y, by przyci¹gn¹æ do siebie u¿ytkowników, aby ci w jak najwiêkszym stopniu korzystali z ich us³ug.

Sposoby dzia³ania systemów rekomendacji mo¿na podzieliæ na ró¿ne sposoby, spoœród których wyodrêbniæ mo¿na dwa najszerzej u¿ywane. S¹ to: filtrowanie kolaboratywne (collaborative filtering) i filtrowanie oparte na treœci (content-based filtering).

\subsection{Filtrowanie kolaboratywne (collaborative filtering)}
Technika ta opiera siê na spostrze¿eniu, i¿ u¿ytkownicy o podobnych preferencjach zachowuj¹ siê podobnie. St¹d je¿eli u¿ytkownik zachowuje siê podobnie do zaobserwowanej wczeœniej grupy u¿ytkowników, mo¿na przewidzieæ jego przeferencje. Istotn¹ zalet¹ tej metody jest fakt, i¿ nie zale¿y ona od dziedziny, w której ulokowany jest system rekomendacji (w przeciwieñstwie do rekomendacji opartych na treœci), a jedynie od zachowañ u¿ytkowników.
\subsection{Filtrowanie oparte na treœci (content-based filtering)}
W technice tej przedmioty polecane u¿ytkownikowi zale¿¹ od innych przedmiotów, na temat których stwierdzono, ¿e u¿ytkownik siê nimi interesuje. Mog¹ siê one opieraæ np. na podobieñstwie przedmiotów: je¿eli u¿ytkownik ,,lubi'' przedmiot A, który jest podobny do przedmiotu ,,B'' to mo¿na spodziewaæ siê, ¿e równie¿ przedmiot B zainteresuje u¿ytkownika. Technika ta jest mocno zale¿na od dziedziny rekomendowanych przedmiotów, gdy¿ wymaga wprowadzenia pewnej miary podobieñstwa miêdzy nimi. St¹d jest trudniejsza do zastosowania, ale daje te¿ mo¿liwoœci nieosi¹galne dla filtrowania kolaboratywnego.

Celem niniejszej pracy jest zbadanie metod sugeruj¹cych u¿ytkownikowi artyku³y podobne do aktualnie odwiedzanego, co wprost wi¹¿e siê z metodami u¿ywanymi w technice filtrowania opartego na treœci.

\section{Techniki przetwarzania jêzyka naturalnego}

Temat niniejszej pracy skupia siê na podobieñstwie pomiêdzy artyku³ami - dokumentami tekstowymi. Ich treœæ zapisana jest w jêzyku naturalnym - zrozumia³ym dla cz³owieka - który mówi¹c potocznie niezrozumia³y dla maszyny. W zwi¹zku z tym koniecznym staje siê tu u¿ycie technik przetwarzania jêzyka naturalnego (natural language processing), które to pozwalaj¹ wyodrêbniæ z tekstu pewne cechy, na bazie których komputer jest w stanie okreœliæ podobiêñstwo pomiêdzy dokumentami (wed³ug pewnej sformalizowanej miary). W poni¿szych paragrafach opisujê techniki przetwarzania jêzyka naturalnego u¿yte przeze mnie wprost lub z których koncepcji czerpa³em.

W celu formalizacji dalszych opisach stosowanych metod stosujê nastêpuj¹ce oznaczenia:
\begin{itemize}
	\item Korpus $C$: zbiór dokumentów $d$,
	\item Dokument $d$: skoñczony ci¹g zdañ $s$,
	\item Zdanie $s$: skoñczony ci¹g s³ów $w$,
	\item S³owo $w$: skoñczony ci¹g znaków $c$,
	\item W celu uproszczenia zapisu: $w \in d \equiv \exists_{s \in d}\ w \in s$,
	\item S³ownik zbudowany na korpusie $C$: $V = {w\ |\ \exists_{d \in C}\ w \in d}$.
\end{itemize}
\subsection{Bag-of-words}
Bag-of-words (worek s³ów) jest metod¹ reprezentacji tekstu jako zbioru zawartych w nim s³ów niezachowuj¹cego kolejnoœci s³ów w tekœcie, lecz liczbê ich wyst¹pieñ. Jako korpus bêdê nazywaæ zbiór przetwarzanych dokumentów, natomiast jako s³ownik zbiór s³ów 

Bag-of-words mo¿na opisaæ jako przekszta³cenie z korpusu w przestrzeñ wektorów $ bow: C \to \mathbb{R}^n $ gdzie:\\
$C$: korpus\\
$m = |C|$: liczba dokumentów w korpusie $C$\\
$V$: s³ownik zbudowany na $C$\\
$n = |V|$: liczba s³ów w $V$\\
$v_i \in \mathbb{R}^n$, gdzie $i \in 1, 2, ..., n$ wektor reprezentuj¹cy dokument $d_i \in C$\\
$v_{ij}$, gdzie $j \in 1, 2, ..., m$: liczba wyst¹pieñ w dokumencie  $d_i \in C$ s³owa $w_j \in V$\\

Technika ta jest stosunkowo prosta jest jej wad¹ jest traktowanie ka¿dego s³owa z jednakow¹ wag¹. Pewne s³owa (np. ,,i'', ,,lub'', ,,o'') wystêpuj¹ bardzo czêsto, lecz ich wk³ad w znaczenie ca³ego dokumentu jest marginalny. St¹d powsta³y bardziej zaawansowane techniki uwzglêdniaj¹ce istotnoœæ s³ów dla znaczenia ca³ego dokumentu.
\subsection{Term frequency - inverted document frequency}
TF-IDF(wa¿enie czêstoœci¹ termów - odwrotna czêstoœæ w dokumentach) jest metod¹ reprezentacji tekstu jako zbioru s³ów przy jednoczesnym uwzglêdnieniu wagi s³ów, która zale¿y od czêstoœci wystêpowania s³owa w korpusie. Oznaczenia formalne takie same tak w przypdku BOW.
$v_{ij} = tfidf_{ij} = tf_{ij} * idf_i$, gdzie:\\
$tf_{ij} = \frac{n_{ij}}{\sum\limits_{k}n_{kj}}$, ,,term frequency'' to liczba wyst¹pieñ s³owa $w_i$ w dokumencie $d_j$ podzielona przez liczbê s³ów dokumentu $d_j$,\\
$idf_i = log\frac{|D|}{|{d:w_i \in d}|}$, ,,inversed document frequecy'' to liczba dokumentów w korpusie podzielona przez liczbê dokumentów zawieraj¹cych przynajmniej jedno wyst¹pienie s³owa $w_i$,

%Ka¿dy dokument reprezentowany jest przez wektor, sk³adaj¹cy siê z wag s³ów wystêpuj¹cych w tym dokumencie. TFIDF informuje o czêstoœci wyst¹pienia termów uwzglêdniaj¹c jednoczeœnie odpowiednie wywa¿enie znaczenia lokalnego termu i jego znaczenia w kontekœcie pe³nej kolekcji dokumentów.

W tej technice s³owa wystêpuj¹ce rzadko s¹ premiowane wzglêdem s³ów pospolitych.
\subsection{Latent Dirichlet Allocation}
%TODO opisaæ metodê


\subsection{Word2vec}%TODO obrazek z sieci¹

Word2vec jest stosunkowo now¹ (2013) metod¹ osadzania s³ów w przestrzeni wektorowej (word embedding), opisan¹ w \cite{word2vec}. 

Autorzy metody proponuj¹ p³ytk¹, dwuwarstwow¹ sieci neuronowej, która ma za zadanie odtworzyæ kontekst danego s³owa. Jako wejœcie metoda otrzymuje s³owa z korpusu. Wyjœciem metody s¹ natomiast wektory z pewnej N wymiarowej przestrzeni odpowiadaj¹ce s³owom   sk³adaj¹cej siê z warstw: wejœciowej, jednej warstwy ukrytej i warstwy wyjœciowej. Wyró¿nia siê dwie architektury sieci: skip-gram: na podstawie s³owa siec przewiduje N s¹siednich s³ów lub CBOW: na postawie okna N s¹siednich s³ów sieæ przewiduje s³owo, którego z najwiêkszym prawdopodobieñstwem te N s³ów jest s¹siedztwem. Wady i zalety obu podejœæ s¹ wymienione w \cite{google_word2vec}

Softmax jest generalizacj¹ funkcji logistycznej, zamieniaj¹c¹ $K$-wymiarowy wektor $z$ dowolnych liczb rzeczywistych na $K$-wymiarowy wektor liczb rzeczywistych z zakresu $(0,1]$, które sumuj¹ siê do $1$\cite{softmax}. Funkcja wyra¿a siê wzorem $\sigma (\mathbf {z} )_{j}={\frac {e^{z_{j}}}{\sum _{k=1}^{K}e^{z_{k}}}}\ dla\ j=1,\ ...,K$. Wyjœcie funkcji mo¿na traktowaæ jako pewien rozk³ad prawdopodobieñstwa.

U¿ywaj¹c tej stosunkowo prostej architektury mo¿na wykonaæ proces nauki u¿ywaj¹c milionów s³ów, których powi¹zania miêdzy sob¹ zostan¹ zachowane w systemie wag sieci neuronowej.


W metodzie word2vec nauka polega na trzenowaniu sieci neuronowe. Jednak¿e w odró¿nieniu od innych metod wykorzystuj¹cych sieci neuronowe, word2vec nie u¿ywa póŸniej wytrenowanej sieci jako takiej, a jedynie otrzymanych w wyniku nauki wag warstwy ukrytej sieæi, które faktycznie s¹ wynikowymi wektorami s³ow.

W dalszym opisie metody szczegó³owo skupiam siê na podejœciu CBOW, lecz podejœcie skip-gram wygl¹da analogicznie.

Sieæ neuronowa bêd¹ca wynikiem nauki przyjmuje na wejœciu wektor binarny d³ugoœci odpowiadaj¹cej liczbie s³ów w s³owniku V zbudowanym na korpusie treningowym. Wektor ten wype³niony jest wartoœciami 0 oraz jedn¹ wartoœci¹ 1 na i-tej pozycji. Taki wektor odpowiada i-temu s³owu ze s³ownika V. Wejœciem sieci s¹ kolejne s³owa z korpusu. Wyjœciem sieci jest wektor tej samej d³ugoœci o wartoœciach rzeczywistych z zakresu [0,1], w którym wartoœæ na i-tej pozycji odpowiada prawdopodobieñstwu, ¿e i-te s³owo ze s³ownika znajduje siê w s¹siedztwie s³owa wejœciowego. Za ,,s¹siedztwo'' wielkoœci x nale¿y tu rozumieæ zbiór z³o¿ony z x s³ów wystêpuj¹cych przed danym s³owem w korpusie i x s³ow po³o¿onych za danym s³owem. Wartoœæ x mo¿e byæ tu ograniczona przez pocz¹tek/koniec zdania, które ograniczaj¹ kontekst danego s³owa.

Jako efekt nale¿y siê spodziewaæ, ¿e dla s³owa wejœciowego ,,Brytania'' otrzymamy na wyjœciu wysok¹ wartoœæ prawdopodobieñstwa dla s³owa ,,Wielka'', a nisk¹ np. dla s³owa ,,skoroszyt''.


Jednym z parametrów metody word2vec jest wymiarowoœæ przestrzeni, w której znajduj¹ siê otrzymane wektory odpowiadaj¹ce s³owom z korpusu. Liczba ta ma swoje Ÿród³o z wielkoœci warstwy warstwy ukrytej sieci neuronowej. Wagi warstwy ukrytej mo¿na interpretowaæ jako macierz MxN, gdzie M to liczba s³ów s³ownika V - wielkoœæ wektowa wejœciowego, a N to liczba neuronów w warstwie ukrytej. Po przeprowadzeniu nauki i-ty wiersz tej macierzy odpowiada wektorowi d³ugoœci N, który reprezentuje i-te s³owo ze s³ownika V.

W sieci nie jest u¿ywa funkcja kakywacji, ale prawdopodobieñstwa na wyjœciu s¹ efektem dzi³ania funkcji softmax.

Funkcja softmax ma tutaj za zadanie sprowadziæ wyjœciowe wartoœci warstwy ukrytej do postaci rozk³adu prawdopodobieñstwa. 

U¿ycie metody Word2vec pozwala oceniæ ,,odleg³oœæ'' pomiêdzy dwoma dokumentami nawet, je¿eli nie posiadaj¹ one wspólnych s³ów. Jest to metoda osadzania (embedding) s³ów w pewnej przestrzeni wektorowej.

\subsection{Odleg³oœæ miêdzy dokumentami}
W celu wykorzystania omówionej metody Word2vec w obszarze tematyki pracy nale¿y wybraæ metodê obliczania odleg³oœci miêdzy dokumentami. Zak³adamy, ¿e je¿eli dystans pomiêdzy dokumentami jest ma³y, to ich tematyka jest podobna.
\subsubsection{Centroid}
Najprostsz¹ i najbardziej intuicyjn¹ metod¹ obliczenia odleg³oœci pomiêdzy wektorow¹ reprezentacj¹ dokumentów jest wykonanie dwóch prostych kroków:
\begin{enumerate}
\item Uœrednienie wektorów wchodz¹cych w sk³ad ka¿dego z dokumentów. Powsta³y w ten sposób wektor jest centroidem reprezentuj¹cym dokument w przestrzeni wektorowej.
\item Obliczenie dystansu miêdzy wektorami. Powszechnie przyjêt¹ praktyk¹ jest stosowanie tzw. odleg³oœci kosinusowej - znormalizowanego iloczynu skalarnego wektorów $A$ i $B$. Jest to kosinus k¹ta pomiêdzy dwoma wektorami reprezentuj¹cymi dokumenty. Zalet¹ tej metody jest natychmiastowa normalizacja wyniku do zakresu $(0, 1)$.  $sim={\mathbf {A} \cdot \mathbf {B}  \over \|\mathbf {A} \|_{2}\|\mathbf {B} \|_{2}}={\frac {\sum \limits _{i=1}^{n}{A_{i}B_{i}}}{{\sqrt {\sum \limits _{i=1}^{n}{A_{i}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{B_{i}^{2}}}}}}$,
 gdzie $A_i$ i $B_i$ s¹ sk³adowymi wektorów odpowiednio $A$ i $B$
\end{enumerate}
Wad¹ opisanej powy¿ej metody jest utrata potencjalnie u¿ytecznych zale¿noœci wektorami wchodz¹cymi w sk³ad dokumentu.

W kontrze to tego prezentujemy metodê liczenia szukanego dystansu uwzglêdniaj¹c¹ rozk³ad wektorów wewn¹tz dokumentu.

\subsubsection{Word Mover's Distance}
Word Mover's Distance\cite{wmd} to stosunkowo nowe rozwi¹zanie (2013) zwracaj¹ce odleg³oœæ miêdzy dokumentami tekstowymi. W tym celu adaptuje algorytm Earth Mover's Distance\cite{emd} oraz wektorow¹ reprezentacjê s³ów dokumentu. WMD mierzy odleg³oœæ miêdzy dokumentami jako minimalny dystans jaki wektory s³ów pierwszego dokumentu musz¹ ,,pokonaæ'' aby osi¹gn¹æ wartoœci wektorów z drugiego dokumantu.

EMD jest metod¹ mierzenia odleg³oœci pomiêdzy dwoma rozk³adami, która opiera siê na minimalnym koszcie, jaki musi zostaæ poniesiony, aby dokonaæ transformacji jednego rozk³adu w drugi. Problem mo¿na sformalizowaæ jako problem programowania liniowego, gdzie:
$P=\{f(p_1,w_{p_1})...(p_m,w_{p_m})\}$, $Q=\{f(q_1,w_{q_1})...(q_n,w_{q_n})\}$ s¹ danymi rozk³adami o $m$ (odpowiednio $n$) klastrach $p_i$ ($q_j$), a $w_{p_i}$ ($w_{q_j}$) jest mas¹ klastra. $D=[d_{ij}]$ jest macierz¹ odleg³oœci, w której $d_{ij}$ reprezentuje odleg³oœæ pomiêdzy klastrami $p_i$ i $q_j$. Celem jest znaleŸæ taki przep³yw $F = [f_{ij}]$, gdzie $f_{ij}$ to przep³yw pomiêdzy $p_i$ i $q_j$, który minimalizuje ca³oœciowy koszt $Work(P, Q, F) = \sum_{i=1}^{m}\sum_{n}^{j=1}d_{ij}f_{ij}$ przo odpowiednich ogramiczeniach\cite{emd_limit}.
EMD jest to dobrze zbadanym problem transportowym\cite{emd}, dla którego powsta³y efektywne metody rozwi¹zania\cite{emd_method}. 

Przypuœæmy, ¿e dziêki metodzie word2vec dla s³ownika $V$ o $n$ s³owach otrzymujemy macierz $X \in \mathbb{R}^{d \times n}$. $i$-ta kolumna tej macierzy reprezentuje $i$-te s³owo ze s³ownika $V$. Odleg³oœci pomiêdzy wektorami reprezentuj¹cymi semantycznie zbli¿one s³owa s¹ relatywnie mniejsze od odleg³oœci dla s³ów niezwi¹zanych ze sob¹. Celem WMD jest zawrzeæ semantyczne podobieñstwo pomiêdzy poszczególnymi parami s³ów w dystans pomiêdzy ca³ymi dokumentami. Aby to osi¹gn¹æ metoda traktuje dokument jako rozk³ad, którego $i$-tym elementem jest liczba wyst¹pieñ $i$-tego s³owa w tym dokumencie, a nastêpnie stosuje metodê EMD do obliczenia dystansu miêdzy tymi rozk³adami. Macierz odleg³oœci $D$ u¿ywana w metodzie EMD jest zbudowana na bazie odleg³oœci miêdzy wektorami Word2vec reprezentuj¹cymi s³owa dokumentów. $d_{ij} = ||x_i-x_j||$, gdzie $i$ i $j$ to indeksy s³ów ze s³ownika $V$ a $x_{ij}$ to element macierzy $X$\cite{wmd}. Autorzy metody okreœlaj¹ z³o¿onoœæ metody jako $O(p^3\log p)$, gdzie $p$ to wielkoœæ s³ownika $V$.


\chapter{Dane}%TODO przerobiæ ca³y rozdzia³
%opis specyfiki danych
Dane, na których testowane by³y opisywane w niniejszej pracy metody otzryma³em dziêki ¿yczliwoœci serwisu e-commerce Allegro. Jednak, by dane te otrzymaæ, zobowi¹zany zosta³em po podpisania umowy o poufnoœci. St¹d, w niniejszej pracy brak jakichkolwiek przyk³adów danych, a jedynie opisy metod u¿ytych do ich przetwarzania i generowania rekomendacji.

%NApisaæ, ¿e w korpusie znajduje siê wiele specyficznych s³ów bran¿owych

Jako, ¿e artyku³y ze zbioru dotycz¹ produktów sprzedawanych za poœrednictwem serwisu Allegro, w sk³ad s³ownika wchodzi wiele s³ów specyficznych dla danej bran¿y. S¹ to m.in. nazwy modeli aparatów: ........., samochodów: ........, gier komputerowych: .........., a tak¿e nazwy techniczne: sprê¿arka, ........ W zwi¹zku z tym zachodzi podejrzenie, ¿e zastosowanie metod wykorzystuj¹cych model nauczony na ogólnym zbiorze tekstu mo¿e nie dawaæ satysfakcjonuj¹cych rezultatów.

\section{Wstêpne przetwarzanie danych}%TODO przeredagowaæ
W celu zwiêkszenia skutecznoœci metod analizy tekstu stosuje siê wstêpne przetwarzanie danych.
Jego techniki nie wchodz¹ w sk³¹d ¿adnego standardu. Wykonujê pewne techniki, opisane ni¿ej, zgodnie z intuicj¹.

Surowe artyku³y odtrzymane od Allegro posiadaj¹ w swej treœci wiele znaczników interpretowanych przez system, na podstawie których wzbogacana jest warstwa wizualna strony internetowej zawieraj¹cej artyku³. Np. obrazki czy ³¹cza do ofert zwi¹zanych z tematem artyku³u. Z punktu widzenia semantycznej analizy tekstu s¹ one bezu¿yteczne, czy wrêcz szkodliwe (powoduj¹ pewne ,,zanieczyszczenie'' tekstu). St¹d usuwam je wykorzystuj¹c odpowiednio skonstruowane wyra¿enia regularne (ich postaæ jest szczegó³em nieistotnym z punktu widzenia tematyki niniejszej pracy).

Kolejnym elemantem wstêpnego pzetwarzania tekstu jest usuniêcie tzw. s³ów stopu (ang. stopwords) - na ogó³ krótkich s³ów nie wnosz¹cych nic do znaczenia ca³oœci artyku³u. S¹ to np. ,,w'', ,,z'', ,,poniewa¿''. Ich usuniêcie zmniejsza liczbê s³ów dokumentu skracaj¹c tym samym czas jego przetwarzania. Jako ¿e s³owa te wystêpuj¹ czêsto, usuniêcie ich daje mo¿liwoœæ uwypuklenia znaczenia innych s³ów maj¹cych wp³yw na rzeczywiste znaczenie ca³ego artyku³u.

Nastêpnie sprowadzam wszystkie s³owa dokumentu do ma³ych liter, ¿eby ujednoliciæ postaæ czêœci s³ów o tym samym znaczeniu, wœród których jedno wystêpuje na pocz¹tku zdania a inne w œrodku.

Kolejnym, najistotniejszym etapem wstêpnego przetwarzania danych jest tzw. tokenizacja, czyli sprowadzanie s³ów o tym samym znaczeniu, a ró¿nej formie gramatycznej do tej samej postaci. Sporym utrudnieniem jest tutaj stopieñ skomplikowania jêzyka polskiego oraz liczba wyj¹tków, jak¹ ten jêzyk posiada. Za przyk³ad mo¿e pos³u¿yæ s³owo ,,mieæ'', którego jedna z form to ,,ma'', kolejna to ,,miej''. Celem etapu jest sprowadzenie ka¿dego z tych wyrazów do formy podstawowej ,,mieæ''. Do przeprowadzenia tej operacji stosujê narzêdzie Morfologik\cite{morfologik}.

U¿ycie wymienionych technik nie jest jedynym standardem a wynikiem analizy przetwarzanych danych i techniki te zosta³y dobrane dla konkretnego przypadku

rozbijanie s³ów po³¹czonych myœlnikiem

Po powy¿szych etepach s³ownik zbudowan na korpusie zawiera 98174 s³ów.

%TODO opisaæ filtracja ekstremalnych s³ów

\section{Opis danych po wstêpnym przetwarzaniu}

%wykonaæ ca³y opis

Opisaæ dok³adnie pola jsona
Napisaæ o koniecznoœci oczyszczenia tekstu z [werew]

W sk³ad faktycznej treœci artyku³u wchodz¹ trzy pola odpowiadaj¹ce za: zawartoœæ, tytu³ i nag³ówek. Pozosta³e pola wykorzystywane przez mnie pola to: s³owa kluczowe i lista kategorii.

Trudnoœci wynikaj¹ce z przetwarzania jêzyka polskiego

Liczba s³ów w korpusie
S³owa rzadkie itp
Rzeczy, które pomijam mo¿na zaznaczyæ, ¿e s¹ tematem osobnych badañ

Ewaluacja rankingów jest zadaniem trudniejszym od oceny np. klasyfikatora.

Jaka by³aby sytuacja idealna - w której ocena nie by³aby problemem

Wspomnieæ, ze kategorie s¹ drzewiaste

Ka¿demu artyku³owi przypisana jest lista kategorii (zawieraj¹cych siê w sobie pod k¹tem szczegó³owoœci) klasyfikuj¹cych artyku³ pod k¹tem poruszanej tematyki. Wszystkie kategorie tworz¹ strukturê drzewiast¹. Jest to wa¿ny element danych poniewa¿ pozwala w póŸniejszym etapie na dokonanie ewaluacji rozwi¹zania.

Jakoœæ danych: czy nie ma luk
Jakoœæ danych oceniam na wysok¹, tj. ka¿de pole zawarte w strukturze dokumentu jest zawsze wype³nione - brak jest wartoœci NULL.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{img/words_hist_log.png}
	\caption{Histogram wyst¹pieñ s³ów w korpusie}
	%\label{fig:warstwy}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{img/articles_length_hist.png}
	\caption{Histogram d³ugoœci artyku³ów.}
	%\label{fig:warstwy}
\end{figure}

\paragraph{}
Otrzymane przeze mnie dane to nieco ponad 20000 dokumentów zapisanych w formacie JSON zawieraj¹cych g³ówn¹ zawartoœæ artyku³u oraz metadane, m.in: id, s³owa kluczowe, kategoria, id autora, tytu³, nag³ówek.


\chapter{Metody ewaluacji}
W celu porównania stosowanych metod wyznaczania podobieñstwa miêdzy artyku³ami konieczna jest formalizacja pewnych miar tego podobieñstwa.

Ewaluacja rankingu, którym trafnoœæ wyników jest zadaniem nietrywialnym. Podobieñstwo artyku³ów napisanych w jêzyku naturalnym jest rzecz¹ subiektywn¹. W sytuacji idealnej dysponowalibyœmy obiektywn¹ miar¹ podobieñstwa pomiêdzy N artyku³ami (np. wyznaczon¹ wczeœniej przez miarodajn¹ grupê u¿ytkowników), które to N artyku³ów stanowi³oby zbiór testowy. Uzyskanie takich danych wi¹¿e siê jednak z du¿ymi kosztami i le¿y poza mo¿liwoœciami autora.

Praktyk¹ umo¿liwiaj¹c¹ obiektywn¹ ocenê, wykorzystywan¹ w dzia³aj¹cych systemach s¹ tzw. testy A/B polegaj¹ce na podziale u¿ytkowników na grupy i zaaplikowaniu ka¿dej grupie innego rozwi¹zania. Nastêpnie mierzone s¹ pewne wskaŸniki wœród ka¿dej grupy (w naszym przypadku np. liczba klikniêæ w artyku³y rekomendowane) i spoœród zgromadzonych wyników wybierane jest rozwi¹zanie najlepsze.

Z powodu braku mo¿liwoœci wykorzystania rzeczywistych u¿ytkowników do ewaluacji rozwi¹zañ jestem zmuszony wprowadziæ w³asne miary oparte na dostêpnych danych.

Nale¿y tu zaznaczyæ niedoskona³oœæ wprowadzanych miar, poniewa¿ ka¿da z nich opiera siê na pewnyh za³o¿eniach, od których prawdziwoœci zlae¿y jakoœæ samej miary.

Dzia³anie testowanych metod mo¿na sformalizwaæ w postaci pewnej funkcji $S_n: C \to \{a_{i}\}_{i < n}$, gdzie $a_i \in C$, a $n$ to liczba elementów zwracanego ci¹gu. Funkcja $S$ przyjmuje artyku³ tekstowy (b¹dŸ jego identyfikator) i zwraca skoñczony ci¹g artyk³ów do niego podobnych zgodnie ze stopniem dopasowania (najlepsze na pocz¹tku). Celem dzia³ania ni¿ej opisanych miar jest ka¿dej parze: wyjœcie-wejœcie funkcji $S$ reprezentuj¹cej testowan¹ metodê przypisaæ ocenê jakoœci zwróconego wyjœcia dla danego wejœcia. Oceny dla konkretnej metody, dla ustalonej próby artyku³ów s¹ nastêpnie uœredniane.

Opisane poni¿ej miary 1 i 2 dokonuj¹ porównania podobieñstwa dla pary artyku³ów. W celu rozszerzenia dzia³ania tych miar do pary wejœcie-wyjœcie metody stosujê œredni¹ wa¿on¹ podobieñstwa kolejnych elementów wyjœcia z wejœciem. Stosowane wagi: $\dfrac{1}{i}$ dla $i=1,\ ...,\ N$, gdzie $N$ to d³ugoœæ ci¹gu wyjœciowego danej metody.


\section{Miara 1: Dystans oparty na metadanych}

Jak wspomnia³em wczeœniej dane prócz treœci artyku³ów zawieraj¹ równie¿ pewne metadane, a wœród nich umo¿liwiaj¹ce tworzenie powi¹zañ miêdzy artyku³ami. Skupiê siê tu na dwóch polach: ,,s³owa kluczowe'' i ,,kategoria''.


\subsection{Kategorie} 

Pierwsz¹ zastosowan¹ miar¹, pozwalaj¹c¹ oceniæ jakoœæ dopasowania podobnych artyku³ów jest ich odleg³oœæ we wczeœniej wspomnianym drzewie kategorii. Zak³adam tu, ¿e im wiêcej wspólnych przodków w drzewie oraz im mniej przodków rozbierzmych, tym bardziej podobe do siebie s¹ artyku³y reprezentowane przez wêz³y drzewa. Zalet¹ miary jest fakt, i¿ przypisanie artyku³u do kategorii zosta³o wykonane przez autora, którego mo¿na okreœliæ ekspertem w danej dziedzinie. St¹d przynale¿noœæ artyku³u do danej kategorii jest mocno uzasadniona. Kolejn¹ zalet¹ tej miary jest fakt, i¿ mo¿na j¹ zastosowaæ automatycznie - wiedza ekspercka jest ju¿ zapisana w danych artyku³ów. Nale¿y zaznaczyæ tu jednak, ¿e miara nie jest idealna - ka¿dy artyku³ nale¿y do tylko jednego liœcia drzewa kategorii. St¹d artyku³ poruszaj¹cy zagadnienia z ró¿nych obszarów, który mo¿na by przypisaæ dwóm stosunkowo odleg³ym kategoriom $A$ i $B$, zostanie przypisany tylko do jednej kategorii, np. $A$. Miara poka¿e wtedy du¿¹ odleg³oœæ od artyku³ów z kategorii $B$, co nie jest prawd¹.

Formalnie miarê mo¿na zapisaæ jako: 
$d(a_1, a_2) = \dfrac{w(a_1,a_2)}{D}$, gdzie $d$ to dystans miêdzy artyku³ami $a_1$ i $a_2$, $w(x, y)$ to d³ugoœæ czêœci wspólnej œcie¿ek od korzenia drzewa kategorii do wêz³ów reprezentuj¹cych artyku³y $x$ i $y$, a $D$ to g³êbokoœæ ca³ego drzewa (wprowadzone w celu normalizacji). Im wy¿szy wynik, tym wiêksze podobieñstwo artyku³ów.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{img/cat_tree_example_1.png}
	\caption{Drzewo kategorii dla przyk³adu 1.}
	%\label{fig:warstwy}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{img/cat_tree_example_2.png}
	\caption{Drzewo kategorii dla przyk³adu 2.}
	%\label{fig:warstwy}
\end{figure}
W powy¿szych przyk³adowych drzewach $w(X, Y) = 1$, $w(Y, Z) = 2$, $D=3$, st¹d $d(X, Y) = \dfrac{1}{3}$, $d(X, Y) = \dfrac{2}{3}$. Miara wskazuje, ¿e artyku³y $X$ i $Y$ s¹ do siebie mniej podobne, ni¿ artyku³y $Y$ i $Z$.

\subsection{S³owa kluczowe}
NIE WIEM, CZY MIARA U¯YWAJ¥CA KEYWORDÓW JEST POTRZEBNA

\section{Miara 2: Ocena przez u¿ytkowników offline}

Kolejn¹ wypracowan¹ miar¹ jest subiektywna ocena ekspercka. W celu obiektywizacji oceny ewaluacja powinna byæ dokonana przez grupê osób operuj¹cycha na tych samych danych. Wad¹ tej metody jest jej powolnoœæ i potrzeba zaanga¿owania dodatkowych osób dokonuj¹cych ewaluacji. Niemo¿liwym wydaje siê przeprowadzenie badania dla wszystkich artyku³ów, st¹d konieczny jest wybór losowej próby artyku³ów, które parami poddane zostan¹ ocenie pod k¹tem podobieñstwa. Skala ocen to 1-10: 1, gdy artyku³y nie s¹ do siebie podobne, 10, gdy podobieñstwo jest ca³kowite.

\section{Miara 3: Historyczna aktywnoœæ u¿ytkowników serwisu}

Zbieranie a nastêpnie przechowywanie informacji o aktywnoœci u¿ytkownika w ramach serwisu internetowego jest powszechn¹ praktyk¹. Proces ten pozwala na analizê zachowania u¿ytkowników co mo¿e doprowadziæ do wniosków, jakie usprawnienia nale¿y przedsiêwzi¹æ, aby spe³niæ cele biznesowe. Jednym z przyk³adów aktywnoœci u¿ytkownika zapisywanej przez serwis Allego s¹ klikniêcia w linki znajduj¹ce siê na stronie internetowej. Informacja ta pozwala sporz¹dziæ jeszcze jedn¹ miarê jakoœci dopasowania podobnych do siebie artyku³ów. Postaæ danych, jakie uda³o mi siê uzyskaæ z serwisu to tabela o polach: adres strony, na której nast¹pi³o klikniêcie, adres strony, na któr¹ prowadzi link, data klikniêcia.

Zalet¹ metody jest, i¿ mo¿na j¹ zastosowaæ automatycznie, lecz jest zale¿na od danych analitycznych pochodz¹cych z serwisu, które s¹ niedoskona³e.

Jak ju¿ zosta³o opisane powy¿ej strona z artyku³em tekstowym zawiera odnoœiki do innych artyku³ów poruszaj¹cych tematykê podobn¹ do danego. Skoro zapisywana jest informacja o przejœciach pomiêdzy podstronami serwisu, to mo¿na policzyæ ile razy z artyku³u X dokonano przejœcia na rekomendowany do niego artyku³ Y1, a ile razy na rekomendowany artyku³ Y2. Je¿eli liczba przejœæ na artyku³ Y1 jest wiêksza ni¿ na Y2, mo¿na wnioskowaæ, i¿ Y1 wydaje siê byæ bardziej adekwatn¹ rekomendacj¹ dla artyku³u X.

Pos³uguj¹c siê powy¿szym za³o¿eniem, mo¿na zaproponowaæ miarê jakoœci rekomendacji generowanych przez testowane metody w odniesieniu do popularnoœci rzeczywistych rekomendacji wyekstrahowanej z danych serwisu o aktywnoœci u¿ytkowników.

W tym celu dokonujê adaptacji miary nDCG (Normalized Discounted Cumulative Gain). Miara ta s³u¿y do oceny jakoœci uszeregowania przedmiotów, np. wyników zwracanych przez silniki
wyszukiwania. 

TUTAJ OPISUJÊ MIARÊ + podajê Ÿród³o
PROBLEM - algorytm allegro zmienia³ siê w czasie

Za³ó¿my, ¿e dany algorytm $A$ zwraca pewien ci¹g artyku³ów $c_A=a1,\ a2,\ ...,\ a6$ podobnych do danego artyku³u $x$, w kolejnoœci od najbardziej adekwatnego. Za³ó¿my równie¿, czêœæ elementów ci¹gu $c_B$ artyku³ów rekomandowanych w serwisie dla $x$ (u¿ywan¹ dotychczas w serwisie metod¹ $B$) znajduje siê równie¿ w ci¹gu $c_A$, tj. np. ISTNIEJ¥ TAKIE $a_i, a_j$ (i, j to indeksy w ci¹gu $c_A$), ¿e nale¿¹ do $c_A$ i $c_B$. Za³ó¿my ponadto, ¿e z danych o klikniêciach u¿ytkowników w linki w ramach serwisu wiadomo, ¿e przejœcie z $x$ na $a_i$ jest bardziej popularne ni¿ przejœcie z $x$ na $a_j$. St¹d je¿eli $i<j$ ($i>j$), to jakoœæ dzia³ania metody $A$ jest dobra (z³a), bo metoda ta generuje podobne artyku³y w kolejnoœci zgodnej ze stopniem podobieñstwa z artyku³em bazowym, opartym o czêstoœc przejœæ u¿ytkowników miêdzy artyku³ami. %TODO DO PRZEREDAGOWANIA!!!!

Za wagi metody nDCG przyjmujê kiczby przejœæ pomiêdzy artyku³ami, a sam¹ metodê stosujê tylko do przeciêcia zbioru artyku³ów podobnych do danego generowanych przez dan¹ metodê ze zborem artyku³ów rekomendowanych do danego przez dotychczasow¹ metodê dzia³aj¹c¹ w serwisie.


\chapter{Opis i wyniki badañ}
\subsection{}
model piaseckiego
ile unikalnych s³ów on nie zawiera
ile wyst¹pieñ s³ów nie zawiera - wykresy

\section{Dalsze badania}
Dalsze badania.

Niniejsza praca nie wyczerpuje sposobów wyboru artyku³ów podobnych. 

Nie wszystkie pola zawarte w strukturze zosta³y wykorzystane: autor

Przed astosowaniem metod wyznaczania podobieñstwa wykona³em przetwarzanie wstêpne dokumentów, które mo¿na przeprowadziæ równie¿ na inne sposoby. Jest to temat osobnych badañ.

Zdajê sobie sprawê z niedoskona³oœci zastosowanych miar...

Tematem niniejszej pracy jest przypisanie danemu artyku³owi artyku³ów najbardziej podobnych. Warto tutaj zaznaczyæ ró¿nicê pomiêdzy tematyk¹ pracy a komercyjnym zagadnieniem najlepszych rekomendacji. Artyku³y, które mo¿na uznaæ za dobre rekomandacje, tj. takie, które przynosz¹ przedsiêbiorstwu najwiêkszy zysk, wcale nie mus¿ byæ podobne do danego. Powszechnym zjawiskiem jest wzbogacanie rekomandacji o przedmioty niepodobne do danego, a pozwalaj¹ce u¿ytkownikowi na poznanie osobnej kategorii przedmiotów, która mo¿e go zainteresowaæ a tym samym przyci¹gn¹æ do serwisu.


%-----------Koniec czêœci zasadniczej-----------
\appendix
\chapter{Technologie i narzêdzie}
\paragraph{}Przy wykonywaniu operacji na tekœcie korzysta³em g³ównie z silnika wyszukiwania Elasticsearch oraz w³asnorêcznie pisanych skryptów w jêzyku Python wykorzystuj¹cych liczne specjalistyczne biblioteki posiadaj¹ce interfejs w tym¿e jêzyku.
wypisaæ póŸniej u¿yte biblioteki

\begin{thebibliography}{11}
%\url{}
\bibitem[1]{handbook}
	Francesco Ricci, Lior Rokach, Bracha Shapira,
	\emph{Introduction to Recommender Systems Handbook},
	Springer,
	2011
\bibitem[2]{slownik}
	S³ownik Jêzyka Polskiego PWN
	\url{http://sjp.pwn.pl/sjp/artykul;2441396.html}
	(07.05.2017)
\bibitem[3]{allegro}
	\url{https://magazyn.allegro.pl/3333-serwis-allegro-to-nasz
	-sposob-na-wasze-szybkie-i-wygodne-zakupy-przez-internet}
	(07.05.2017)
\bibitem[4]{morfologik}
	\url{http://morfologik.blogspot.com/}
	(07.05.2017)
\bibitem[5]{word2vec}
	Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean,
	\emph{Efficient Estimation of Word Representations in Vector Space},
	International Conference on Machine Learning (ICML),
	2013
\bibitem[6]{google_word2vec}
	\url{https://code.google.com/archive/p/word2vec/}
	(26.05.2017)
\bibitem[7]{word2vec_tutorial}
	\url{http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/}
	26.05.2017)
\bibitem[9]{emd_method}
	Ofir Pele, Michael Werman,
	\emph{Fast and robust earth mover's distances},
	ICCV,
	2009
\bibitem[10]{emd}
	Yossi Rubner, Carlo Tomasi, and Leonidas J. Guibas,
	\emph{The Earth Mover's Distance as a Metric for Image Retrieval},
	str. 1,
	Computer Science Department, Stanford University,
	2000
\bibitem[11]{emd_limit}
	Yossi Rubner, Carlo Tomasi, and Leonidas J. Guibas,
	\emph{The Earth Mover's Distance as a Metric for Image Retrieval},
	str. 8,
	Computer Science Department, Stanford University,
	2000
\bibitem[12]{wmd}
	Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger,
	\emph{From Word Embeddings To Document Distances},
	International Conference on Machine Learning (ICML),
	2015
\bibitem[13]{softmax}
	\url{https://en.wikipedia.org/wiki/Softmax_function/}
	(11.06.2017)
\bibitem[14]{screen_allegro}
	\url{https://allegro.pl/artykul/jaka-farba-dla-alergika-55917/}
	(26.06.2017)
\end{thebibliography}

\appendix
%\chapter{Instrukcja u¿ytkownika}
%\paragraph{}
\clearpage
\pagestyle{empty}
\noindent Warszawa, dnia ...............
\vspace{5cm}
\begin{center}
\LARGE{Oœwiadczenie}
\end{center}
Oœwiadczam, ¿e pracê magistersk¹ pod tytu³em: ,,Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce'', której promotorem jest dr in¿. Anna Wróblewska, wykona³em samodzielnie, co poœwiadczam w³asnorêcznym podpisem.
\vspace{2cm}
\begin{flushright}
...........................................
\end{flushright}
\end{document}