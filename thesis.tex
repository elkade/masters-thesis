\documentclass[12pt, twoside, openany]{report}
\usepackage[dvips]{graphicx,color,rotating}
\usepackage[cp1250]{inputenc}
\usepackage{t1enc}
\usepackage{a4wide}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{verbatim}
%\usepackage[MeX]{polski}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{left=25mm,right=25mm,bindingoffset=10mm, top=25mm, bottom=25mm}
\usepackage{amssymb, latexsym}
\usepackage{amsthm}
\usepackage{palatino}
\usepackage{array}
\usepackage{pstricks}
\usepackage{textcomp}
\usepackage{float}
\usepackage[none]{hyphenat}
\usepackage[english, polish]{babel}
\usepackage{hyperref}
\theoremstyle{definition}
\newtheorem{theorem}{Twierdzenie}[section]
\newtheorem{remark}{Uwaga}[section]
\newtheorem{definition}{Definicja}[section]
\newtheorem{alg}{Algorytm}[chapter]
\newtheorem{prz}{Przypadek}[section]
\newtheorem{np}{Przyk³ad}[section]
\newtheorem{lemma}[theorem]{Lemat}
\linespread{1.5}
\newcommand*{\norm}[1]{\left\Vert{#1}\right\Vert}
\newcommand*{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand*{\om}{\omega}
\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\\}
%\renewcommand{\floatpagefraction}{.99}%
\author{£ukasz Dragan}
\title{Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce}

\begin{document}
\sloppy
\hyphenpenalty 10000
\exhyphenpenalty 10000
\righthyphenmin 10000
\lefthyphenmin 10000
\hyphenchar\font=-1
% Za³ó³æ gêœl¹ jaŸñ.
\begin{titlepage}
\pagestyle{empty}

\noindent
\begin{Large}
\begin{table}[t]
\centering
\begin{tabular}[t]{lcr}
 \includegraphics[width=70pt,height=70pt]{PW} & POLITECHNIKA WARSZAWSKA & \includegraphics[width=70pt,height=70pt]{MiNI}\\
& WYDZIA£ MATEMATYKI & \\
& I NAUK INFORMACYJNYCH &
\end{tabular}
\end{table}

\begin{center}PRACA DYPLOMOWA MAGISTERSKA\end{center}
\begin{center}INFORMATYKA\end{center}\end{Large}
\begin{center}
\Large
\textbf{Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce}
\vfill
\large
\textbf{Content-based recommendations in e-commerce services}
\vfill
\normalsize
Autor:\\
\LARGE
£ukasz Dragan
\vfill
\normalsize
Promotor: 
\large
dr in¿. Anna Wróblewska
\vfill
\large
Warszawa, czerwiec 2017
\end{center}
\newpage
\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}


% \maketitle
\end{titlepage}
\thispagestyle{empty}
\newpage
\pagestyle{headings}
\setcounter{page}{1}
\hyphenation{Syl-ves-tra}
\hyphenation{Syl-ves-ter-a}

\begin{abstract}
\paragraph{}
W niniejszej pracy zajmujê siê porównaniem metod wyszukiwania podobnych do siebie artyku³ów tekstowych. Celem jest znalezienie w oparciu o treœæ danego artyku³u podobnych artyku³ów, które mo¿naby zarekomendowaæ u¿ytkownikowi przegl¹daj¹cemu dany artyku³. Problem zaczerpniêty jest z serwisu aukcyjnego Allegro, który posiada dzia³ artyku³ów opisuj¹cych produkty dostêpne w serwisie. Dzia³ ten posiada system rekomendacji dopasowuj¹cy do danego artyku³u listê artyku³ów, które s¹ do niego najbardziej podobne i mog¹ zainteresowaæ u¿ytkownika. W swojej pracy staram siê przeanalizowaæ i zaaplikowaæ znane metody wyszukiwania podobnych dokumentów tekstowych oraz porównaæ rezultaty. Skupiam siê szczególnie na metodach opartych o semantyczn¹ analizê tekstu.

\end{abstract}

\begin{otherlanguage}{english}
\begin{abstract}
\paragraph{} xcfghdfghhdfghfdgh
\paragraph{} dfgdsfgsdfgsdfgds
\end{abstract}
\end{otherlanguage}
\tableofcontents
\clearpage

%-----------Pocz¹tek czêœci zasadniczej-----------

\chapter{Wstêp}

\section{}


Systemy rekomendacji s¹ powszechnym elementem wielu serwisów internetowych. Sprawdzaj¹ siê w takich polach jak polecanie produktów w sklepie czy rekomendacje ofert pracy. Daj¹ u¿ytkownikowi poczucie indywidualnego traktowania przez serwis internetowy dopasowuj¹cy niejako zawartoœæ swoich stron to konkretnego u¿ytkownika. Pozwalato u¿ytkownikowi na bardziej efektywne korzystanie z serwisu. Mo¿e to prowadziæ do wiêkszego zaanga¿owania ze strony u¿ytkownika i przywi¹zania do serwisu. Systemy rekomendacji daj¹ obopuln¹ korzyœæ zarówno u¿ytkownikowi jak i w³aœcicielowi serwisu internetowego.

Tematem mojej pracy magisterskiej jest stworzenie mechanizmu dopasowuj¹cego podobne do danego artyku³y tekstowe w oparciu o ich treœæ. Szczegó³owy problem poruszany w pracy pochodzi z serwisu Allegro posiadaj¹cego dzia³ artyku³ów opisuj¹cych produkty dostêpne w serwisie. W celu zachêcenia u¿ytkownika do dalszej lektury artyku³ów stosuje siê mechanizm rekomendacji podobnych artyku³ów. Celem niniejszej pracy jest zbadanie i udoskonalenie obecnego w serwisie mechanizmu generowania rekomendacji. 


W swojej pracy korzystam z metod przetwarzania jêzyka naturalnego a w tym z metod semantycznej analizy tekstu.


Podczas prowadzenia badañ stworzy³em szereg skryptów przetwarzaj¹cych dane i wykorzystuj¹cych implementacje opisywanych poni¿ej metod. Opis u¿ytych narzêdzi programistycznych i bibliotek zawar³em w dodatku A do niniejszej pracy.

\section{Rekomendacje artyku³ów tekstowych w Allegro}

Allegro jest najwiêksz¹ dzia³aj¹c¹ na rynku polskim platform¹ aukcyjn¹ on-line. Posiada ponad 20 mln zarejestrowanych klientów. Ka¿dego dnia na Allegro sprzedaje siê ponad 870 tysiêcy przedmiotów. Zatrudnia 1300 pracowników.\cite{allegro} Serwis umo¿liwia u¿ytkownikom wystawianie na sprzeda¿ oraz kupno przedmiotów poprzez mechanizm licytacji lub natychmiastowego zakupu. Allegro pobiera prowizjê za dokonanie sprzeda¿y za swoim poœrednictwem.

Oprócz g³ównej czêœci serwisu odpowiedzialnej za transakcje Allegro posiada dzia³ zajmuj¹cy siê publikacj¹ artyku³ów opisuj¹cych produkty wystawiane za poœrednictwem serwisu. Ma to na celu pomoc u¿ytkownikom przy wyborze interesuj¹cego ich produktu.

Po to, aby zachêciæ u¿ytkowników do zapoznania siê z treœci¹ kolejnych artyku³ów, zastosowany zosta³ tu system rekomendacji przyporz¹dkowuj¹cy danemu artyku³owi listê powi¹zanych artyku³ów. Kryterium mówi¹cym, czy artyku³y s¹ powi¹zane jest tutaj jedynie treœæ artyku³ów a nie wczeœciejsze zachowanie u¿ytkownika.

W celu unikniêcia nieporozumieñ pragnê tutaj zaznaczyæ ró¿nicê pomiêdzy znaczeniami s³owa ,,artyku³'', które mo¿e oznaczaæ zarówno tekst publicystyczny, literacki lub naukowy jak i rzecz, która jest przedmiotem handlu.\cite{slownik} W niniejszej pracy skupiam siê na rekomendacjach artyku³ów tekstowych, st¹d u¿ywam pierwszego znaczenia (chyba, ¿e inne znaczenie jest wyraŸnie zaznaczone).

Od serwisu Allegro otrzyma³em zserializowan¹ kopiê 20000 artyku³ów dostêpnych na stronach serwisu. Pojedynczy artyku³ sk³ada siê z g³ównej zawartoœci tekstowej oraz pewnych metadanych. W celu otrzymania wszelkich danych od firmy Allegro wynagane by³o, abym podpisa³ umowê, w której zobowi¹zujê siê do nieujawniania ¿adnych danych, które otrzyma³em. St¹d opisy danych, na których pracujê, zawarte w tej pracy nie wnikaj¹ w ich szczwg³óy i nieodbiegaj¹ od informacji publicznie dostêpnych przez stronê allegro.pl.

W niniejszej pracy wykonujê eksperymenty wykorzystuj¹c znane metody okreœlania podobieñstw pomiêdzy dokumentami, które adaptujê do zbioru dokumentów, które otrzyma³em od serwisu Allegro.

W obszarze, którym zajmuje siê niniejsza praca, bezpoœrednim celem rekomendacji jest, aby u¿ytkownik odwiedza³ kolejne podstrony serwisu, co wprost zwiêksza szansê na dokonanie przez niego transakcji.

Obecnie wykorzystywana metoda generowania rekomendacji artyku³ów opiera siê o zapytanie do us³ugi Elasticsearch. Elasticsearch jest popularnym silnikiem wyszukiwania tekstu opartym o indeks Lucene. Dzia³a w architekturze rozproszonej a komunikacja z nim nastêpuje poprzez protokó³ HTTP i format JSON.

Metoda ta ogranicza siê jednak jedynie do wyszukiwania tekstowego pomijaj¹c zagadnienia semantyczne. Znaczy to, ¿e je¿eli dwa teksty opisuj¹ ten sam temat, ale u¿ywaj¹ to tego ró¿nych s³ów, np. synonimów, to systemowi opartemu jedynie o wyszukiwanie tekstowe nie uda siê stwierdziæ podobieñstwa miêdzy tymi tekstami, mimo, i¿ takowe istnieje.

St¹d w mojej pracy postanowi³em wykonaæ eksperymenty z metodami u¿ywaj¹cymi semantycznej analizy tekstu, aby oceniæ, czy daj¹ one lepsze rezultaty od obecnie stosowanej metody.

W niniejszej pracy skupiam siê g³ównie na podejœciu word2vec z racji tego, i¿ powsta³ niedawno.


Dochodzenie nowych rekomendacji - nie jest tematem pracy
-------------------

S³owa, które zostaj¹ po tokenizacji to np literówki

\section{Struktura pracy}
Rozdzia³ 2 wprowadza do zagadnienia rekomendacji i opisuje wybrane metody przetwarzania jêzyka naturalnego s³u¿¹ce do wyszukiwania podobieñstw miêdzy dokumentami tekstowymi.

Nastêpnie w rozdziale 3 dokonujê opisu konkretnego problemu, jakim jest generacja rekomendacji artyku³ów tekstowych w serwisie Allegro. Opisujê dane otrzymane z serwisu oraz kolejne wstêpnego etapy przetwarzania ich, aby nadawa³y siê do zaaplikowania do nich wybranych metod.

Dalej, w rozdziale 4 opisujê proces zastosowania wybranych metod oraz porównanie efektów ich dzia³ania. Opisujê równie¿ u¿yte metody ewaluacji wyników.

Ostatecznie dokonujê podsumowania przeprowadzonych badañ i rozwa¿am kierunki dalszych prac w tej dziedzinie.
\chapter{Przegl¹d wybranych metod}

W swojej pracy wykorzystujê i adaptujê do swoich potrzeb szereg metod i narzêdzi umo¿liwiaj¹cych przetwarzanie jêzyka naturalnego, semantyczn¹ analizê tekstu i wykrywanie podobieñstwa pomiêdzy tekstami. Czêœæ z nich (metoda tf-idf, bag-of-words, silnik Elasticsearch) jest od lat powszechnie wykorzystywana w zadaniu wyszukiwania tekstowego. Inne z kolei - korzystaj¹ce z semantycznej analizy tekstu - nie tak popularne z powodu swojej nowoœci, b¹dŸ trudnoœci w zaaplikowaniu. Daje to pole do badañ i ewentualnych usprawnieñ istniej¹cych systemów opieraj¹cych siê o klasyczne metody. Wybrane metody stosujê, zgodnie z tematem pracy, w zadaniu generowania rekomendacji, st¹d przegl¹d metod zaczynam w³aœnie od wprowadzenia do tego zagadnienia.

\section{Systemy rekomendacji}

Systemy rekomendacji to narzêdzia i techniki maj¹ce na celu zasugerowaæ u¿ytkownikowi przedmioty. Sugestie te odnosz¹ siê do ró¿nych procesów podejmowania decyzji takich jak np. które artyku³y kupiæ, jakiej muzyki s³uchaæ czy te¿ które wiadomoœci czytaæ. ,,Przedmiot'' jest tutaj ogólnym pojêciem oznaczaj¹cym coœ, co system poleca u¿ytkownikowi. \cite{handbook} 

Przy wci¹¿ wzrastaj¹cej iloœci danych u¿ytkownicy serwisów internetowych czêsto nie s¹ w stanie dotrzeæ do informacji, która ich interesuje. Jest to pole do rozwoju zautomatyzowanych systemów rekomendacyjnych polecaj¹cych u¿ytkownikom treœci, które mog¹ ich zainterezowaæ. Dzia³alnoœæ tekiego systemu daj zysk zarówn u¿ytkownikowi, pozwalaj¹c mu dotrzeæ do informacji, której móg³by samodzielnie nie odszukaæ, albo wrêcz nie wiedzieæ, i¿ taka informacja istnieje, jak i dla w³aœcicieli serwisów internetowych, którym zale¿y, by przyci¹gn¹æ do siebie u¿ytkowników, aby ci w jak najwiêkszym stopniu korzystali z ich us³ug.

Sposoby dzia³ania systemów rekomendacji mo¿na podzieliæ na ró¿ne sposoby, spoœród których wyodrêbniæ mo¿na dwa najszerzej u¿ywane. S¹ to: filtrowanie kolaboratywne (collaborative filtering) i filtrowanie oparte na treœci (content-based filtering).

\subsection{Filtrowanie kolaboratywne (collaborative filtering)}
Technika ta opiera siê na spostrze¿eniu, i¿ u¿ytkownicy o podobnych preferencjach zachowuj¹ siê podobnie. St¹d je¿eli u¿ytkownik zachowuje siê podobnie do zaobserwowanej wczeœniej grupy u¿ytkowników, mo¿na przewidzieæ jego przeferencje. Istotn¹ zalet¹ tej metody jest fakt, i¿ nie zale¿y ona od dziedziny, w której ulokowany jest system rekomendacji (w przeciwieñstwie do rekomendacji opartych na treœci), a jedynie od zachowañ u¿ytkowników.
\subsection{Filtrowanie oparte na treœci (content-based filtering)}
W technice tej przedmioty polecane u¿ytkownikowi zale¿¹ od innych przedmiotów, na temat których stwierdzono, ¿e u¿ytkownik siê nimi interesuje. Mog¹ siê one opieraæ np. na podobieñstwie przedmiotów: je¿eli u¿ytkownik ,,lubi'' przedmiot A, który jest podobny do przedmiotu ,,B'' to mo¿na spodziewaæ siê, ¿e równie¿ przedmiot B zainteresuje u¿ytkownika. Technika ta jest mocno zale¿na od dziedziny rekomendowanych przedmiotów, gdy¿ wymaga wprowadzenia pewnej miary podobieñstwa miêdzy nimi. St¹d jest trudniejsza do zastosowania, ale daje te¿ mo¿liwoœci nieosi¹galne dla filtrowania kolaboratywnego.

Celem niniejszej pracy jest zbadanie metod sugeruj¹cych u¿ytkownikowi artyku³y podobne do aktualnie odwiedzanego, co wprost wi¹¿e siê z metodami u¿ywanymi w technice filtrowania opartego na treœci.

\section{Techniki przetwarzania jêzyka naturalnego}

Temat niniejszej pracy skupia siê na podobieñstwie pomiêdzy artyku³ami - dokumentami tekstowymi. Ich treœæ zapisana jest w jêzyku naturalnym - zrozumia³ym dla cz³owieka - który mówi¹c potocznie niezrozumia³y dla maszyny. W zwi¹zku z tym koniecznym staje siê tu u¿ycie technik przetwarzania jêzyka naturalnego (natural language processing), które to pozwalaj¹ wyodrêbniæ z tekstu pewne cechy, na bazie których komputer jest w stanie okreœliæ podobiêñstwo pomiêdzy dokumentami (wed³ug pewnej sformalizowanej miary).

W poni¿szych paragrafach opisujê techniki przetwarzania jêzyka naturalnego u¿yte przeze mnie wprost lub 

W celu formalizacji dalszych opisach stosowanych metod stosujê nastêpuj¹ce



Korpus $C$: zbiór dokumentów $d$,\\
Dokument $d$: skoñczony ci¹g zdañ $s$,\\
Zdanie $s$: skoñczony ci¹g s³ów $w$,\\
S³owo $w$: skoñczony ci¹g znaków $c$,\\
W celu uproszczenia zapisu: $w \in d \equiv \exists_{s \in d}\ w \in s$,\\
S³ownik zbudowany na korpusie $C$: $V = {w\ |\ \exists_{d \in C}\ w \in d}$.\\


\subsection{Bag-of-words}
Bag-of-words (worek s³ów) jest metod¹ reprezentacji tekstu jako zbioru zawartych w nim s³ów niezachowuj¹cego kolejnoœci s³ów w tekœcie, lecz liczbê ich wyst¹pieñ. Jako korpus bêdê nazywaæ zbiór przetwarzanych dokumentów, natomiast jako s³ownik zbiór s³ów 



Bag-of-words mo¿na opisaæ jako przekszta³cenie z korpusu w przestrzeñ wektorów $ bow: C \to \mathbb{R}^n $ gdzie:\\
$C$: korpus\\
$m = |C|$: liczba dokumentów w korpusie $C$\\
$V$: s³ownik zbudowany na $C$\\
$n = |V|$: liczba s³ów w $V$\\
$v_i \in \mathbb{R}^n$, gdzie $i \in 1, 2, ..., n$ wektor reprezentuj¹cy dokument $d_i \in C$\\
$v_{ij}$, gdzie $j \in 1, 2, ..., m$: liczba wyst¹pieñ w dokumencie  $d_i \in C$ s³owa $w_j \in V$\\

Ka¿dy dokument reprezentowany jest przez wektor, sk³adaj¹cy siê z wag s³ów wystêpuj¹cych w tym dokumencie. TFIDF informuje o czêstoœci wyst¹pienia termów uwzglêdniaj¹c jednoczeœnie odpowiednie wywa¿enie znaczenia lokalnego termu i jego znaczenia w kontekœcie pe³nej kolekcji dokumentów.


 W celu sprowadzenia korpusu do reprezentacji bag-of-words 


Technika ta jest stosunkowo prosta jest jej wad¹ jest traktowanie ka¿dego s³owa z jednakow¹ wag¹. Pewne s³owa (np. ,,i'', ,,lub'', ,,o'') wystêpuj¹ bardzo czêsto, lecz ich wk³ad w znaczenie ca³ego dokumentu jest marginalny. St¹d powsta³y bardziej zaawansowane techniki uwzglêdniaj¹ce istotnoœæ s³ów dla znaczenia ca³ego dokumentu.
\subsection{Term frequency - inverted document frequency}
TF-IDF(wa¿enie czêstoœci¹ termów - odwrotna czêstoœæ w dokumentach) jest metod¹ reprezentacji tekstu jako zbioru s³ów przy jednoczesnym uwzglêdnieniu wagi s³ów, która zale¿y od czêstoœci wystêpowania s³owa w korpusie. Oznaczenia formalne takie same tak w przypdku BOW.
$v_{ij} = tfidf_{ij} = tf_{ij} * idf_i$, gdzie:\\
$tf_{ij} = \frac{n_{ij}}{\sum\limits_{k}n_{kj}}$, ,,term frequency'' to liczba wyst¹pieñ s³owa $w_i$ w dokumencie $d_j$ podzielona przez liczbê s³ów dokumentu $d_j$,\\
$idf_i = log\frac{|D|}{|{d:w_i \in d}|}$, ,,inversed document frequecy'' to liczba dokumentów w korpusie podzielona przez liczbê dokumentów zawieraj¹cych przynajmniej jedno wyst¹pienie s³owa $w_i$
W tej technice s³owa wystêpuj¹ce rzadko s¹ premiowane wzglêdem s³ów pospolitych.
\subsection{Latent Dirichlet Allocation}



\subsection{Word2vec}
Word2vec jest stosunkowo now¹ (2013) metod¹ osadzania s³ów w przestrzeni wektorowej (word embedding), opisan¹ w \cite{word2vec}. 

Autorzy metody proponuj¹ p³ytk¹, dwuwarstwow¹ sieci neuronowej, która ma za zadanie odtworzyæ kontekst danego s³owa. Jako wejœcie metoda otrzymuje s³owa z korpusu. Wyjœciem metody s¹ natomiast wektory z pewnej N wymiarowej przestrzeni odpowiadaj¹ce s³owom   sk³adaj¹cej siê z warstw: wejœciowej, jednej warstwy ukrytej i warstwy wyjœciowej. Wyró¿nia siê dwie architektury sieci: skip-gram: na podstawie s³owa siec przewiduje N s¹siednich s³ów lub CBOW: na postawie okna N s¹siednich s³ów sieæ przewiduje s³owo, którego z najwiêkszym prawdopodobieñstwem te N s³ów jest s¹siedztwem. Wady i zalety obu podejœæ s¹ wymienione w \cite{google_word2vec}

Softmax jest generalizacj¹ funkcji logistycznej, zamieniaj¹c¹ $K$-wymiarowy wektor $z$ dowolnych liczb rzeczywistych na $K$-wymiarowy wektor liczb rzeczywistych z zakresu $(0,1]$, które sumuj¹ siê do $1$\cite{softmax}. Funkcja wyra¿a siê wzorem $\sigma (\mathbf {z} )_{j}={\frac {e^{z_{j}}}{\sum _{k=1}^{K}e^{z_{k}}}}\ dla\ j=1,\ ...,K$. Wyjœcie funkcji mo¿na traktowaæ jako pewien rozk³ad prawdopodobieñstwa.

U¿ywaj¹c tej stosunkowo prostej architektury mo¿na wykonaæ proces nauki u¿ywaj¹c milionów s³ów, których powi¹zania miêdzy sob¹ zostan¹ zachowane w systemie wag sieci neuronowej.


W metodzie word2vec nauka polega na trzenowaniu sieci neuronowe. Jednak¿e w odró¿nieniu od innych metod wykorzystuj¹cych sieci neuronowe, word2vec nie u¿ywa póŸniej wytrenowanej sieci jako takiej, a jedynie otrzymanych w wyniku nauki wag warstwy ukrytej sieæi, które faktycznie s¹ wynikowymi wektorami s³ow.

W dalszym opisie metody szczegó³owo skupiam siê na podejœciu CBOW, lecz podejœcie skip-gram wygl¹da analogicznie.

Sieæ neuronowa bêd¹ca wynikiem nauki przyjmuje na wejœciu wektor binarny d³ugoœci odpowiadaj¹cej liczbie s³ów w s³owniku V zbudowanym na korpusie treningowym. Wektor ten wype³niony jest wartoœciami 0 oraz jedn¹ wartoœci¹ 1 na i-tej pozycji. Taki wektor odpowiada i-temu s³owu ze s³ownika V. Wejœciem sieci s¹ kolejne s³owa z korpusu. Wyjœciem sieci jest wektor tej samej d³ugoœci o wartoœciach rzeczywistych z zakresu [0,1], w którym wartoœæ na i-tej pozycji odpowiada prawdopodobieñstwu, ¿e i-te s³owo ze s³ownika znajduje siê w s¹siedztwie s³owa wejœciowego. Za ,,s¹siedztwo'' wielkoœci x nale¿y tu rozumieæ zbiór z³o¿ony z x s³ów wystêpuj¹cych przed danym s³owem w korpusie i x s³ow po³o¿onych za danym s³owem. Wartoœæ x mo¿e byæ tu ograniczona przez pocz¹tek/koniec zdania, które ograniczaj¹ kontekst danego s³owa.

Jako efekt nale¿y siê spodziewaæ, ¿e dla s³owa wejœciowego ,,Brytania'' otrzymamy na wyjœciu wysok¹ wartoœæ prawdopodobieñstwa dla s³owa ,,Wielka'', a nisk¹ np. dla s³owa ,,skoroszyt''.


Jednym z parametrów metody word2vec jest wymiarowoœæ przestrzeni, w której znajduj¹ siê otrzymane wektory odpowiadaj¹ce s³owom z korpusu. Liczba ta ma swoje Ÿród³o z wielkoœci warstwy warstwy ukrytej sieci neuronowej. Wagi warstwy ukrytej mo¿na interpretowaæ jako macierz MxN, gdzie M to liczba s³ów s³ownika V - wielkoœæ wektowa wejœciowego, a N to liczba neuronów w warstwie ukrytej. Po przeprowadzeniu nauki i-ty wiersz tej macierzy odpowiada wektorowi d³ugoœci N, który reprezentuje i-te s³owo ze s³ownika V.

W sieci nie jest u¿ywa funkcja kakywacji, ale prawdopodobieñstwa na wyjœciu s¹ efektem dzi³ania funkcji softmax.

Funkcja softmax ma tutaj za zadanie sprowadziæ wyjœciowe wartoœci warstwy ukrytej do postaci rozk³adu prawdopodobieñstwa. 

U¿ycie metody Word2vec pozwala oceniæ ,,odleg³oœæ'' pomiêdzy dwoma dokumentami nawet, je¿eli nie posiadaj¹ one wspólnych s³ów. Jest to metoda osadzania (embedding) s³ów w pewnej przestrzeni wektorowej.

\subsection{Odleg³oœæ miêdzy dokumentami}
W celu wykorzystania omówionej metody Word2vec w obszarze tematyki pracy nale¿y wybraæ metodê obliczania odleg³oœci miêdzy dokumentami. Zak³adamy, ¿e je¿eli dystans pomiêdzy dokumentami jest ma³y, to ich tematyka jest podobna.
\subsubsection{Centroid}
Najprostsz¹ i najbardziej intuicyjn¹ metod¹ obliczenia odleg³oœci pomiêdzy wektorow¹ reprezentacj¹ dokumentów jest wykonanie dwóch prostych kroków:
\begin{enumerate}
\item Uœrednienie wektorów wchodz¹cych w sk³ad ka¿dego z dokumentów. Powsta³y w ten sposób wektor jest centroidem reprezentuj¹cym dokument w przestrzeni wektorowej.
\item Obliczenie dystansu miêdzy wektorami. Powszechnie przyjêt¹ praktyk¹ jest stosowanie tzw. odleg³oœci kosinusowej - znormalizowanego iloczynu skalarnego wektorów $A$ i $B$. Jest to kosinus k¹ta pomiêdzy dwoma wektorami reprezentuj¹cymi dokumenty. Zalet¹ tej metody jest natychmiastowa normalizacja wyniku do zakresu $(0, 1)$.  $sim={\mathbf {A} \cdot \mathbf {B}  \over \|\mathbf {A} \|_{2}\|\mathbf {B} \|_{2}}={\frac {\sum \limits _{i=1}^{n}{A_{i}B_{i}}}{{\sqrt {\sum \limits _{i=1}^{n}{A_{i}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{B_{i}^{2}}}}}}$,
 gdzie $A_i$ i $B_i$ s¹ sk³adowymi wektorów odpowiednio $A$ i $B$
\end{enumerate}
Wad¹ opisanej powy¿ej metody jest utrata potencjalnie u¿ytecznych zale¿noœci wektorami wchodz¹cymi w sk³ad dokumentu.

W kontrze to tego prezentujemy metodê liczenia szukanego dystansu uwzglêdniaj¹c¹ rozk³ad wektorów wewn¹tz dokumentu.

\subsubsection{Word Mover's Distance}
Word Mover's Distance\cite{wmd} to stosunkowo nowe rozwi¹zanie (2013) zwracaj¹ce odleg³oœæ miêdzy dokumentami tekstowymi. W tym celu adaptuje algorytm Earth Mover's Distance\cite{emd} oraz wektorow¹ reprezentacjê s³ów dokumentu. WMD mierzy odleg³oœæ miêdzy dokumentami jako minimalny dystans jaki wektory s³ów pierwszego dokumentu musz¹ ,,pokonaæ'' aby osi¹gn¹æ wartoœci wektorów z drugiego dokumantu.

EMD jest metod¹ mierzenia odleg³oœci pomiêdzy dwoma rozk³adami, która opiera siê na minimalnym koszcie, jaki musi zostaæ poniesiony, aby dokonaæ transformacji jednego rozk³adu w drugi. Problem mo¿na sformalizowaæ jako problem programowania liniowego, gdzie:
$P=\{f(p_1,w_{p_1})...(p_m,w_{p_m})\}$, $Q=\{f(q_1,w_{q_1})...(q_n,w_{q_n})\}$ s¹ danymi rozk³adami o $m$ (odpowiednio $n$) klastrach $p_i$ ($q_j$), a $w_{p_i}$ ($w_{q_j}$) jest mas¹ klastra. $D=[d_{ij}]$ jest macierz¹ odleg³oœci, w której $d_{ij}$ reprezentuje odleg³oœæ pomiêdzy klastrami $p_i$ i $q_j$. Celem jest znaleŸæ taki przep³yw $F = [f_{ij}]$, gdzie $f_{ij}$ to przep³yw pomiêdzy $p_i$ i $q_j$, który minimalizuje ca³oœciowy koszt $Work(P, Q, F) = \sum_{i=1}^{m}\sum_{n}^{j=1}d_{ij}f_{ij}$ przo odpowiednich ogramiczeniach\cite{emd_limit}.
EMD jest to dobrze zbadanym problem transportowym\cite{emd}, dla którego powsta³y efektywne metody rozwi¹zania\cite{emd_method}. 

Przypuœæmy, ¿e dziêki metodzie word2vec dla s³ownika $V$ o $n$ s³owach otrzymujemy macierz $X \in \mathbb{R}^{d \times n}$. $i$-ta kolumna tej macierzy reprezentuje $i$-te s³owo ze s³ownika $V$. Odleg³oœci pomiêdzy wektorami reprezentuj¹cymi semantycznie zbli¿one s³owa s¹ relatywnie mniejsze od odleg³oœci dla s³ów niezwi¹zanych ze sob¹. Celem WMD jest zawrzeæ semantyczne podobieñstwo pomiêdzy poszczególnymi parami s³ów w dystans pomiêdzy ca³ymi dokumentami. Aby to osi¹gn¹æ metoda traktuje dokument jako rozk³ad, którego $i$-tym elementem jest liczba wyst¹pieñ $i$-tego s³owa w tym dokumencie, a nastêpnie stosuje metodê EMD do obliczenia dystansu miêdzy tymi rozk³adami. Macierz odleg³oœci $D$ u¿ywana w metodzie EMD jest zbudowana na bazie odleg³oœci miêdzy wektorami Word2vec reprezentuj¹cymi s³owa dokumentów. $d_{ij} = ||x_i-x_j||$, gdzie $i$ i $j$ to indeksy s³ów ze s³ownika $V$ a $x_{ij}$ to element macierzy $X$\cite{wmd}. Autorzy metody okreœlaj¹ z³o¿onoœæ metody jako $O(p^3\log p)$, gdzie $p$ to wielkoœæ s³ownika $V$.


\chapter{Dane}
Dane, na których testowane by³y opisywane w niniejszej pracy metody otzryma³em dziêki ¿yczliwoœci serwisu e-commerce Allegro. Jednak, by dane te otrzymaæ, zobowi¹zany zosta³em po podpisania umowy o poufnoœci. St¹d, w niniejszej pracy brak jakichkolwiek przyk³adów danych, a jedynie opisy metod u¿ytych do ich przetwarzania i generowania rekomendacji.

NApisaæ, ¿e w korpusie znajduje siê wiele specyficznych s³ów bran¿owych

Jako, ¿e artyku³y ze zbioru dotycz¹ produktów sprzedawanych za poœrednictwem serwisu Allegro, w sk³ad s³ownika wchodzi wiele s³ów specyficznych dla danej bran¿y. S¹ to m.in. nazwy modeli aparatów: !!!!!!!!!!!!!, samochodów: !!!!!!!!!!!!!, gier komputerowych: !!!!!!!!!!!!!, a tak¿e nazwy techniczne: sprê¿arka, !!!!!!!!!!!!!!!!!!!!. W zwi¹zku z tym zachodzi podejrzenie, ¿e zastosowanie metod wykorzystuj¹cych model nauczony na ogólnym zbiorze tekstu mo¿e nie dawaæ satysfakcjonuj¹cych rezultatów.

\paragraph{} 
\begin{figure}[H]
  \centering
    \includegraphics[width=1\textwidth]{img/words_hist_log.png}
  \caption{Histogram wyst¹pieñ s³ów w korpusie}
  %\label{fig:warstwy}
\end{figure}
\begin{figure}[H]
  \centering
    \includegraphics[width=1\textwidth]{img/articles_length_hist.png}
  \caption{Histogram d³ugoœci artyku³ów.}
  %\label{fig:warstwy}
\end{figure}

\section{Wstêpne przetwarzanie danych}
A celu zwiêkszenia skutecznoœci metod analizy tekstu stosuje siê wstêpne przetwarzanie danych.
Jego techniki nie wchodz¹ w sk³¹d ¿adnego standardu. Wykonujê pewne techniki, opisane ni¿ej, zgodnie z intuicj¹.

Surowe artyku³y odtrymane od Allegro posiadaj¹ w swej treœci wiele znaczników interpretowanych przez system, na podstawie których wzbogacana jest warstwa wizualna strony internetowej zawiraj¹cej artyku³. Np. obrazki czy ³¹cza do ofert zwi¹zanych z tematem artyku³u. Z punktu widzenia semantycznej analizy tekstu s¹ one bezu¿yteczne, czy wrêcz szkodliwe (powoduj¹ pewne ,,zanieczyszczenie'' tekstu). St¹d usuwam je wykorzystuj¹c odpowiednio skonstruowane wyra¿enia regularne (ich postaæ jest szczegó³em nieistotnym z punktu widzenia tematyki niniejszej pracy).

Kolejnym elemantem wstêpnego pzetwarzania tekstu jest usuniêcie tzw. s³ów stopu (ang. stopwords) - na ogó³ krótkich s³ów nie wnosz¹cych nic do znaczenia ca³oœci artyku³u. S¹ to np. ,,w'', ,,z'', ,,poniewa¿''. Ich usuniêcie zmniejsza liczbê s³ów dokumentu skracaj¹c tym samym czas jego przetwarzania. Jako ¿e s³owa te wystêpuj¹ czêsto, usuniêcie ich daje mo¿liwoœæ uwypuklenia znaczenia innych s³ów maj¹cych wp³yw na rzeczywiste znaczenie ca³ego artyku³u.

Nastêpnie sprowadzam wszystkie s³owa dokumentu do ma³ych liter, ¿eby ujednoliciæ postaæ czêœci s³ów o tym samym znaczeniu, wœród których jedno wystêpuje na pocz¹tku zdania a inne w œrodku.

Kolejnym, najistotniejszym etapem wstêpnego przetwarzania danych jest tzw. tokenizacja, czyli sprowadzanie s³ów o tym samym znaczeniu, a ró¿nej formie gramatycznej do tej samej postaci. Sporym utrudnieniem jest tutaj stopieñ skomplikowania jêzyka polskiego oraz liczba wyj¹tków, jak¹ ten jêzyk posiada. Za przyk³ad mo¿e pos³u¿yæ s³owo ,,mieæ'', którego jedna z form to ,,ma'', kolejna to ,,miej''. Celem etapu jest sprowadzenie ka¿dego z tych wyrazów do formy podstawowej ,,mieæ''. Do przeprowadzenia tej operacji stosujê narzêdzie Morfologik\cite{morfologik}.

U¿ycie wymienionych technik nie jest jedynym standardem a wynikiem analizy przetwarzanych danych i techniki te zosta³y dobrane dla konkretnego przypadku

rozbijanie s³ów po³¹czonych myœlnikiem

Po powy¿szych etepach s³ownik zbudowan na korpusie zawiera 98174 s³ów.

filtracja ekstremalnych s³ów

\section{Opis danych po wstêpnym przetwarzaniu}


Opisaæ dok³adnie pola jsona
Napisaæ o koniecznoœci oczyszczenia tekstu z [werew]

W sk³ad faktycznej treœci artyku³u wchodz¹ trzy pola odpowiadaj¹ce za: zawartoœæ, tytu³ i nag³ówek. Pozosta³e pola wykorzystywane przez mnie pola to: s³owa kluczowe i lista kategorii.

Trudnoœci wynikaj¹ce z przetwarzania jêzyka polskiego

Liczba s³ów w korpusie
S³owa rzadkie itp
Rzeczy, które pomijam mo¿na zaznaczyæ, ¿e s¹ tematem osobnych badañ

Ewaluacja rankingów jest zadaniem trudniejszym od oceny np. klasyfikatora.

Jaka by³aby sytuacja idealna - w której ocena nie by³aby problemem

Wspomnieæ, ze kategorie s¹ drzewiaste

Ka¿demu artyku³owi przypisana jest lista kategorii (zawieraj¹cych siê w sobie pod k¹tem szczegó³owoœci) klasyfikuj¹cych artyku³ pod k¹tem poruszanej tematyki. Wszystkie kategorie tworz¹ strukturê drzewiast¹. Jest to wa¿ny element danych poniewa¿ pozwala w póŸniejszym etapie na dokonanie ewaluacji rozwi¹zania.

Jakoœæ danych: czy nie ma luk
Jakoœæ danych oceniam na wysok¹, tj. ka¿de pole zawarte w strukturze dokumentu jest zawsze wype³nione - brak jest wartoœci NULL.


\paragraph{}
Otrzymane przeze mnie dane to nieco ponad 20000 dokumentów zapisanych w formacie JSON zawieraj¹cych g³ówn¹ zawartoœæ artyku³u oraz metadane, m.in: id, s³owa kluczowe, kategoria, id autora, tytu³, nag³ówek.


\section{Metody ewaluacji}

Ewaluacja

W celu porównania stosowanych metod wyznaczania podobieñstwa miêdzy artyku³ami konieczna jest formalizacja pewnej miary tego podobieñstwa.

Ewaluacja rankingu, którym niew¹dfgdg .. jest zadaniem nietrywialnym. Podobieñstwo artyku³ów napisanych w jêzyku naturalnym jest rzecz¹ subiektywn¹. W sytuacji idealnej dysponowalibyœmy obiektywn¹ miar¹ podobieñstwa pomiêdzy N artyku³ami (np. wyznaczon¹ wczeœniej przez miarodajn¹ grupê u¿ytkowników), które to N artyku³ów stanowi³oby zbiór testowy. Uzyskanie takich danych wi¹¿e siê jednak z du¿ymi kosztami i le¿y poza mo¿liwoœciami autora.

Praktyk¹ umo¿liwiaj¹c¹ obiektywn¹ ocenê, wykorzystywan¹ w dzia³aj¹cych systemach s¹ tzw. testy A/B polegaj¹ce na podziale u¿ytkowników na grupy i zaaplikowaniu ka¿dej grupie innego rozwi¹zania. Nastêpnie mierzone s¹ pewne wskaŸniki wœród ka¿dej grupy (w naszym przypadku np. liczba klikniêæ w artyku³y rekomendowane) i spoœród zgromadzonych wyników wybierane jest rozwi¹zanie najlepsze.

Z powodu braku mo¿liwoœci wykorzystania rzeczywistych u¿ytkowników do ewaluacji rozwi¹zañ jestem zmuszony wprowadziæ w³asne miary oparte na dostêpnych danych.

Miara 1: jak daleko pod wzglêdem kategorii jesteœmy

Pierwsz¹ zastosowan¹ miar¹, pozwalaj¹c¹ oceniæ jakoœæ dopasowania podobnych artyku³ów jest ich odleg³oœæ ww wczeœniej wspomnianym drzewie kategorii: im mniejszy dystans pomiêdzy liœæmi drzewa, tym wiêksze podobieñstwo pomiêdzy artyku³ami. Zalet¹ miary jest fakt, i¿ przypisanie artyku³u do kategorii zosta³o wykonane przez autora, którego mo¿na okreœliæ ekspertem w danej dziedzinie, st¹d przynale¿noœæ artyku³u do danej kategorii jest obiektywnie uzasadniona. Kolejn¹ zalet¹ tej miary (w odró¿nieniu od nastêpnej) jest fakt, i¿ mo¿na j¹ zastosowaæ automatycznie - wiedza ekspercka jest ju¿ zapisana w danych artyku³ów. Nale¿y zaznaczyæ tu jednak, ¿e miara nie jest idealna - ka¿dy artyku³ nale¿y do tylko jednego liœcia drzewa kategorii. St¹d artyku³ poruszaj¹cy zagadnienia z ró¿nych obszarów, który mo¿na by przypisaæ dwóm stosunkowo odleg³ym kategoriom A i B, zostanie przypisany tylko do jednej kategorii, np. A. Miara poka¿e wtedy du¿¹ odleg³oœæ od artyku³ów z kategorii B, co nie jest prawd¹.

Miara 2: subiektywna - trzeba wymyœliæ jak¹œ punktacjê

Kolejn¹ wprowadzon¹ miar¹ jest subiektywna ocena ekspercka. W celu obiektywizacji oceny ewaluacja powinna byæ dokonana przez wiêcej ni¿ jedn¹ osobê. Wad¹ tej metody jest jej powolnoœæ i potrzeba zaanga¿owania dodatkowych osób dokonuj¹cych ewaluacji. Niemo¿liwym wydaje siê przeprowadzenie badania dla wszystkich artyku³ów, st¹d konieczny jest wybór losowej próby artyku³ów, które poddane zostan¹ ocenie.

Miara 3: kliki

\section{Wyniki badañ}
\subsection{}
model piaseckiego
ile unikalnych s³ów on nie zawiera
ile wyst¹pieñ s³ów nie zawiera - wykresy

\section{Dalsze badania}
Dalsze badania.

Niniejsza praca nie wyczerpuje sposobów wyboru artyku³ów podobnych. 

Nie wszystkie pola zawarte w strukturze zosta³y wykorzystane: autor

Przed astosowaniem metod wyznaczania podobieñstwa wykona³em przetwarzanie wstêpne dokumentów, które mo¿na przeprowadziæ równie¿ na inne sposoby. Jest to temat osobnych badañ.

Zdajê sobie sprawê z niedoskona³oœci zastosowanych miar...

Tematem niniejszej pracy jest przypisanie danemu artyku³owi artyku³ów najbardziej podobnych. Warto tutaj zaznaczyæ ró¿nicê pomiêdzy tematyk¹ pracy a komercyjnym zagadnieniem najlepszych rekomendacji. Artyku³y, które mo¿na uznaæ za dobre rekomandacje, tj. takie, które przynosz¹ przedsiêbiorstwu najwiêkszy zysk, wcale nie mus¿ byæ podobne do danego. Powszechnym zjawiskiem jest wzbogacanie rekomandacji o przedmioty niepodobne do danego, a pozwalaj¹ce u¿ytkownikowi na poznanie osobnej kategorii przedmiotów, która mo¿e go zainteresowaæ a tym samym przyci¹gn¹æ do serwisu.


%-----------Koniec czêœci zasadniczej-----------
\appendix
\chapter{Technologie i narzêdzie}
\paragraph{}Przy wykonywaniu operacji na tekœcie korzysta³em g³ównie z silnika wyszukiwania Elasticsearch oraz w³asnorêcznie pisanych skryptów w jêzyku Python wykorzystuj¹cych liczne specjalistyczne biblioteki posiadaj¹ce interfejs w tym¿e jêzyku.
wypisaæ póŸniej u¿yte biblioteki

\begin{thebibliography}{11}
%\url{}
\bibitem[1]{handbook}
	Francesco Ricci, Lior Rokach, Bracha Shapira,
	\emph{Introduction to Recommender Systems Handbook},
	Springer,
	2011
\bibitem[2]{slownik}
	S³ownik Jêzyka Polskiego PWN
	\url{http://sjp.pwn.pl/sjp/artykul;2441396.html}
	(07.05.2017)
\bibitem[3]{allegro}
	\url{https://magazyn.allegro.pl/3333-serwis-allegro-to-nasz
	-sposob-na-wasze-szybkie-i-wygodne-zakupy-przez-internet}
	(07.05.2017)
\bibitem[4]{morfologik}
	\url{http://morfologik.blogspot.com/}
	(07.05.2017)
\bibitem[5]{word2vec}
	Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean,
	\emph{Efficient Estimation of Word Representations in Vector Space},
	International Conference on Machine Learning (ICML),
	2013
\bibitem[6]{google_word2vec}
	\url{https://code.google.com/archive/p/word2vec/}
	(26.05.2017)
\bibitem[7]{word2vec_tutorial}
	\url{http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/}
	26.05.2017)
\bibitem[9]{emd_method}
	Ofir Pele, Michael Werman,
	\emph{Fast and robust earth mover's distances},
	ICCV,
	2009
\bibitem[10]{emd}
	Yossi Rubner, Carlo Tomasi, and Leonidas J. Guibas,
	\emph{The Earth Mover's Distance as a Metric for Image Retrieval},
	str. 1,
	Computer Science Department, Stanford University,
	2000
\bibitem[11]{emd_limit}
	Yossi Rubner, Carlo Tomasi, and Leonidas J. Guibas,
	\emph{The Earth Mover's Distance as a Metric for Image Retrieval},
	str. 8,
	Computer Science Department, Stanford University,
	2000
\bibitem[12]{wmd}
	Matt J. Kusner, Yu Sun, Nicholas I. Kolkin, Kilian Q. Weinberger,
	\emph{From Word Embeddings To Document Distances},
	International Conference on Machine Learning (ICML),
	2015
\bibitem[13]{softmax}
	\url{https://en.wikipedia.org/wiki/Softmax_function/}
	(11.06.2017)
\end{thebibliography}

\appendix
%\chapter{Instrukcja u¿ytkownika}
%\paragraph{}
\clearpage
\pagestyle{empty}
\noindent Warszawa, dnia ...............
\vspace{5cm}
\begin{center}
\LARGE{Oœwiadczenie}
\end{center}
Oœwiadczam, ¿e pracê magistersk¹ pod tytu³em: ,,Rekomendacje artyku³ów opisuj¹cych produkty w serwisach e-commerce'', której promotorem jest dr in¿. Anna Wróblewska, wykona³em samodzielnie, co poœwiadczam w³asnorêcznym podpisem.
\vspace{2cm}
\begin{flushright}
...........................................
\end{flushright}
\end{document}